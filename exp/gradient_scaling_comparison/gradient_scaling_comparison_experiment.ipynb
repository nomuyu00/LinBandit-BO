{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 勾配報酬スケーリングの効果検証実験\n",
    "\n",
    "この実験では、勾配ベース報酬に対してL_hatスケーリングを適用する効果を検証します：\n",
    "\n",
    "1. **スケーリングあり**: L_hatスケーリング + 勾配ベース報酬 + 0.5x arms\n",
    "2. **スケーリングなし**: 勾配ベース報酬（スケーリングなし） + 0.5x arms\n",
    "\n",
    "両アルゴリズムは以下の共通設定を使用：\n",
    "- 勾配ベース報酬（GPモデルの勾配の絶対値）\n",
    "- 0.5x arms（次元数の半分のアーム数）\n",
    "- coordinate_ratio=0.8\n",
    "\n",
    "テスト関数：\n",
    "- Styblinski-Tang\n",
    "- Rastrigin\n",
    "- Ackley\n",
    "\n",
    "各関数について20回の独立実行を行い、L_hatスケーリングの純粋な効果を評価します。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:11:18.051349Z",
     "start_time": "2025-07-22T04:11:17.977639Z"
    }
   },
   "source": "import math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport os\nfrom copy import deepcopy\nimport pandas as pd\n\n# BoTorch / GPyTorch\nfrom botorch import fit_gpytorch_model\nfrom botorch.models import SingleTaskGP\nfrom gpytorch.mlls import ExactMarginalLogLikelihood\nfrom gpytorch.kernels import RBFKernel, ScaleKernel\nfrom botorch.acquisition import ExpectedImprovement\nfrom botorch.optim import optimize_acqf\n\n# デフォルトのdtypeをfloat32に設定\ntorch.set_default_dtype(torch.float32)\n\n# プロット設定\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams['figure.figsize'] = (12, 8)\n\n# 日本語フォント設定\n# 方法1: japanize-matplotlibを試す\ntry:\n    import japanize_matplotlib\nexcept ImportError:\n    # 方法2: 手動でフォントを設定\n    import matplotlib\n    # Windowsの場合\n    if os.name == 'nt':\n        plt.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo']\n    # macOSの場合\n    elif os.uname().sysname == 'Darwin':\n        plt.rcParams['font.family'] = ['Hiragino Sans', 'Hiragino Maru Gothic Pro']\n    # Linuxの場合\n    else:\n        plt.rcParams['font.family'] = ['IPAGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP', 'TakaoGothic']\n    \n    plt.rcParams['axes.unicode_minus'] = False\n\n# フォント設定の確認\nprint(f\"使用フォント: {plt.rcParams['font.family']}\")\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# 出力フォルダの作成\noutput_dir = \"output_results_gradient_scaling_comparison\"\nos.makedirs(output_dir, exist_ok=True)\n\nprint(\"実験環境の設定完了\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# スケーリングあり版LinBandit-BO（固定L_hatスケーリング + 勾配ベース + 0.5x arms）\nclass GradientLinBanditBO_WithFixedScaling:\n    \"\"\"\n    勾配報酬 + 固定L_hatスケーリングあり版LinBandit-BO\n    \"\"\"\n    \n    def __init__(self, objective_function, bounds, n_initial=5, n_max=100, \n                 coordinate_ratio=0.8, n_arms=None, fixed_L_hat=100.0):\n        self.objective_function = objective_function\n        self.bounds = bounds.float()\n        self.dim = bounds.shape[1]\n        self.n_initial = n_initial\n        self.n_max = n_max\n        self.coordinate_ratio = coordinate_ratio\n        \n        # 0.5x arms設定\n        self.n_arms = n_arms if n_arms is not None else max(1, self.dim // 2)\n        \n        # Linear Banditのパラメータ\n        self.A = torch.eye(self.dim)\n        self.b = torch.zeros(self.dim)\n        \n        # 初期点の生成\n        self.X = torch.rand(n_initial, self.dim) * (bounds[1] - bounds[0]) + bounds[0]\n        self.X = self.X.float()\n        \n        # 状態変数\n        self.Y = None\n        self.best_value = None\n        self.best_point = None\n        self.model = None\n        self.eval_history = []\n        self.theta_history = []\n        self.scale_init = 1.0\n        self.total_iterations = 0\n        \n        # 固定リプシッツ定数\n        self.L_hat = fixed_L_hat\n        \n        # 報酬履歴の記録\n        self.reward_history = []\n        self.scaled_reward_history = []\n        \n    def update_model(self):\n        \"\"\"ガウス過程モデルの更新\"\"\"\n        kernel = ScaleKernel(\n            RBFKernel(ard_num_dims=self.X.shape[-1], dtype=torch.float32),\n            dtype=torch.float32, noise_constraint=1e-3\n        ).to(self.X)\n        self.model = SingleTaskGP(self.X, self.Y, covar_module=kernel)\n        mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)\n        fit_gpytorch_model(mll)\n        \n    def initialize(self):\n        \"\"\"初期化：初期点での評価とモデル構築\"\"\"\n        y_val = self.objective_function(self.X)\n        self.Y = y_val.unsqueeze(-1).float()\n        \n        # スケーリング係数の計算\n        y_max, y_min = self.Y.max().item(), self.Y.min().item()\n        self.scale_init = (y_max - y_min) if (y_max - y_min) != 0 else 1.0\n        \n        # モデルの初期化\n        self.update_model()\n        \n        # 最良点の初期化\n        post_mean = self.model.posterior(self.X).mean.squeeze(-1)\n        bi = post_mean.argmin()\n        self.best_value = post_mean[bi].item()\n        self.best_point = self.X[bi]\n        self.eval_history = [self.best_value] * self.n_initial\n        \n    def generate_arms(self):\n        \"\"\"アーム生成（0.5x arms）\"\"\"\n        num_coord = int(self.coordinate_ratio * self.n_arms)\n        num_coord = min(num_coord, self.dim)\n        \n        # ランダムに座標を選択\n        idxs = np.random.choice(self.dim, num_coord, replace=False)\n        \n        # 座標方向の生成\n        coords = []\n        for i in idxs:\n            e = torch.zeros(self.dim, device=self.X.device)\n            e[i] = 1.0\n            coords.append(e)\n            \n        coord_arms = torch.stack(coords, 0) if coords else torch.zeros(0, self.dim, device=self.X.device)\n        \n        # ランダム方向の生成\n        num_rand = self.n_arms - num_coord\n        rand_arms = torch.randn(num_rand, self.dim, device=self.X.device) if num_rand > 0 else torch.zeros(0, self.dim, device=self.X.device)\n        \n        if num_rand > 0:\n            norms = rand_arms.norm(dim=1, keepdim=True)\n            rand_arms = torch.where(norms > 1e-9, rand_arms / norms, \n                                   torch.randn_like(rand_arms) / (torch.randn_like(rand_arms).norm(dim=1,keepdim=True)+1e-9))\n            \n        return torch.cat([coord_arms, rand_arms], 0)\n    \n    def select_arm(self, arms_features):\n        \"\"\"Linear UCBによる方向選択\"\"\"\n        # LinUCBパラメータ\n        sigma = 1.0\n        L = 1.0\n        lambda_reg = 1.0\n        delta = 0.1\n        S = 1.0\n        \n        # 現在のパラメータ推定\n        A_inv = torch.inverse(self.A)\n        theta = A_inv @ self.b\n        self.theta_history.append(theta.clone())\n        \n        # 信頼幅の計算\n        current_round_t = max(1, self.total_iterations)\n        log_term_numerator = max(1e-9, 1 + (current_round_t - 1) * L**2 / lambda_reg)\n        beta_t = (sigma * math.sqrt(self.dim * math.log(log_term_numerator / delta)) + \n                  math.sqrt(lambda_reg) * S)\n        \n        # UCBスコアの計算\n        ucb_scores = []\n        for i in range(arms_features.shape[0]):\n            x = arms_features[i].view(-1, 1)\n            mean = (theta.view(1, -1) @ x).item()\n            try:\n                var = (x.t() @ A_inv @ x).item()\n            except torch.linalg.LinAlgError:\n                var = (x.t() @ torch.linalg.pinv(self.A) @ x).item()\n                \n            ucb_scores.append(mean + beta_t * math.sqrt(max(var, 0)))\n            \n        return int(np.argmax(ucb_scores))\n    \n    def propose_new_x(self, direction):\n        \"\"\"選択された方向に沿った最適化\"\"\"\n        ei = ExpectedImprovement(self.model, best_f=self.best_value, maximize=False)\n        \n        # 方向に沿った探索範囲の計算\n        active_dims_mask = direction.abs() > 1e-9\n        if not active_dims_mask.any():\n            lb, ub = -1.0, 1.0\n        else:\n            ratios_lower = (self.bounds[0] - self.best_point) / (direction + 1e-12 * (~active_dims_mask))\n            ratios_upper = (self.bounds[1] - self.best_point) / (direction + 1e-12 * (~active_dims_mask))\n            \n            t_bounds = torch.zeros(self.dim, 2, device=self.X.device)\n            t_bounds[:, 0] = torch.minimum(ratios_lower, ratios_upper)\n            t_bounds[:, 1] = torch.maximum(ratios_lower, ratios_upper)\n            \n            lb = -float('inf')\n            ub = float('inf')\n            for i in range(self.dim):\n                if active_dims_mask[i]:\n                    lb = max(lb, t_bounds[i, 0].item())\n                    ub = min(ub, t_bounds[i, 1].item())\n                    \n        if lb > ub:\n            domain_width = (self.bounds[1, 0] - self.bounds[0, 0]).item()\n            lb = -0.1 * domain_width\n            ub = 0.1 * domain_width\n            \n        one_d_bounds = torch.tensor([[lb], [ub]], dtype=torch.float32, device=self.X.device)\n        \n        def ei_on_line(t_scalar_tensor):\n            t_values = t_scalar_tensor.squeeze(-1)\n            points_on_line = self.best_point.unsqueeze(0) + t_values.reshape(-1, 1) * direction.unsqueeze(0)\n            points_on_line_clamped = torch.clamp(points_on_line, self.bounds[0].unsqueeze(0), self.bounds[1].unsqueeze(0))\n            return ei(points_on_line_clamped.unsqueeze(1))\n        \n        # 獲得関数の最適化\n        cand_t, _ = optimize_acqf(\n            ei_on_line,\n            bounds=one_d_bounds,\n            q=1,\n            num_restarts=10,\n            raw_samples=100\n        )\n        \n        alpha_star = cand_t.item()\n        new_x = self.best_point + alpha_star * direction\n        new_x_clamped = torch.clamp(new_x, self.bounds[0], self.bounds[1])\n        \n        return new_x_clamped\n    \n    def optimize(self):\n        \"\"\"メインの最適化ループ\"\"\"\n        # 初期化\n        self.initialize()\n        n_iter = self.n_initial\n        \n        while n_iter < self.n_max:\n            self.total_iterations += 1\n            \n            # 探索方向の候補生成\n            arms_features = self.generate_arms()\n            \n            # Linear UCBによる方向選択\n            sel_idx = self.select_arm(arms_features)\n            direction = arms_features[sel_idx]\n            \n            # 選択された方向に沿った最適化\n            new_x = self.propose_new_x(direction)\n            \n            # 予測と実際の評価\n            with torch.no_grad():\n                predicted_mean = self.model.posterior(new_x.unsqueeze(0)).mean.squeeze().item()\n            actual_y = self.objective_function(new_x.unsqueeze(0)).squeeze().item()\n            \n            # 報酬の計算（勾配ベース + 固定L_hatスケーリング）\n            new_x_for_grad = new_x.clone().unsqueeze(0)\n            new_x_for_grad.requires_grad_(True)\n            \n            # GPモデルで事後分布を取得\n            posterior = self.model.posterior(new_x_for_grad)\n            mean_at_new_x = posterior.mean\n            \n            # 勾配を計算\n            mean_at_new_x.sum().backward()\n            grad_vector = new_x_for_grad.grad.squeeze(0)\n            \n            # 報酬ベクトルを定義\n            reward_vector = grad_vector.abs()\n            \n            # 報酬を記録\n            self.reward_history.append(reward_vector.clone().detach().cpu().numpy())\n            \n            # 固定リプシッツ定数でスケーリング\n            scaled_reward_vector = reward_vector / self.L_hat\n            \n            # スケーリングされた報酬を記録\n            self.scaled_reward_history.append(scaled_reward_vector.clone().detach().cpu().numpy())\n            \n            # Linear Banditパラメータの更新\n            x_arm = direction.view(-1, 1)\n            self.A += x_arm @ x_arm.t()\n            self.b += scaled_reward_vector\n            \n            # データとモデルの更新\n            self.X = torch.cat([self.X, new_x.unsqueeze(0)], 0)\n            self.Y = torch.cat([self.Y, torch.tensor([[actual_y]], dtype=torch.float32, device=self.X.device)], 0)\n            self.update_model()\n            \n            # 最良点の更新\n            with torch.no_grad():\n                posterior_mean = self.model.posterior(self.X).mean.squeeze(-1)\n            current_best_idx = posterior_mean.argmin()\n            self.best_value = posterior_mean[current_best_idx].item()\n            self.best_point = self.X[current_best_idx]\n            \n            self.eval_history.append(self.best_value)\n            n_iter += 1\n                \n        return self.best_point, self.best_value\n\nprint(\"固定スケーリングあり版LinBandit-BOクラスの定義完了\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:11:18.127921Z",
     "start_time": "2025-07-22T04:11:18.098903Z"
    }
   },
   "source": [
    "# スケーリングあり版LinBandit-BO（L_hatスケーリング + 勾配ベース + 0.5x arms）\n",
    "class GradientLinBanditBO_WithScaling:\n",
    "    \"\"\"\n",
    "    勾配報酬 + L_hatスケーリングあり版LinBandit-BO\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, objective_function, bounds, n_initial=5, n_max=100, \n",
    "                 coordinate_ratio=0.8, n_arms=None):\n",
    "        self.objective_function = objective_function\n",
    "        self.bounds = bounds.float()\n",
    "        self.dim = bounds.shape[1]\n",
    "        self.n_initial = n_initial\n",
    "        self.n_max = n_max\n",
    "        self.coordinate_ratio = coordinate_ratio\n",
    "        \n",
    "        # 0.5x arms設定\n",
    "        self.n_arms = n_arms if n_arms is not None else max(1, self.dim // 2)\n",
    "        \n",
    "        # Linear Banditのパラメータ\n",
    "        self.A = torch.eye(self.dim)\n",
    "        self.b = torch.zeros(self.dim)\n",
    "        \n",
    "        # 初期点の生成\n",
    "        self.X = torch.rand(n_initial, self.dim) * (bounds[1] - bounds[0]) + bounds[0]\n",
    "        self.X = self.X.float()\n",
    "        \n",
    "        # 状態変数\n",
    "        self.Y = None\n",
    "        self.best_value = None\n",
    "        self.best_point = None\n",
    "        self.model = None\n",
    "        self.eval_history = []\n",
    "        self.theta_history = []\n",
    "        self.scale_init = 1.0\n",
    "        self.total_iterations = 0\n",
    "        \n",
    "        # 推定リプシッツ定数（スケーリングあり）\n",
    "        self.L_hat = 1.0\n",
    "        \n",
    "    def update_model(self):\n",
    "        \"\"\"ガウス過程モデルの更新\"\"\"\n",
    "        kernel = ScaleKernel(\n",
    "            RBFKernel(ard_num_dims=self.X.shape[-1], dtype=torch.float32),\n",
    "            dtype=torch.float32, noise_constraint=1e-3\n",
    "        ).to(self.X)\n",
    "        self.model = SingleTaskGP(self.X, self.Y, covar_module=kernel)\n",
    "        mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)\n",
    "        fit_gpytorch_model(mll)\n",
    "        \n",
    "    def initialize(self):\n",
    "        \"\"\"初期化：初期点での評価とモデル構築\"\"\"\n",
    "        y_val = self.objective_function(self.X)\n",
    "        self.Y = y_val.unsqueeze(-1).float()\n",
    "        \n",
    "        # スケーリング係数の計算\n",
    "        y_max, y_min = self.Y.max().item(), self.Y.min().item()\n",
    "        self.scale_init = (y_max - y_min) if (y_max - y_min) != 0 else 1.0\n",
    "        \n",
    "        # モデルの初期化\n",
    "        self.update_model()\n",
    "        \n",
    "        # 最良点の初期化\n",
    "        post_mean = self.model.posterior(self.X).mean.squeeze(-1)\n",
    "        bi = post_mean.argmin()\n",
    "        self.best_value = post_mean[bi].item()\n",
    "        self.best_point = self.X[bi]\n",
    "        self.eval_history = [self.best_value] * self.n_initial\n",
    "        \n",
    "    def generate_arms(self):\n",
    "        \"\"\"アーム生成（0.5x arms）\"\"\"\n",
    "        num_coord = int(self.coordinate_ratio * self.n_arms)\n",
    "        num_coord = min(num_coord, self.dim)\n",
    "        \n",
    "        # ランダムに座標を選択\n",
    "        idxs = np.random.choice(self.dim, num_coord, replace=False)\n",
    "        \n",
    "        # 座標方向の生成\n",
    "        coords = []\n",
    "        for i in idxs:\n",
    "            e = torch.zeros(self.dim, device=self.X.device)\n",
    "            e[i] = 1.0\n",
    "            coords.append(e)\n",
    "            \n",
    "        coord_arms = torch.stack(coords, 0) if coords else torch.zeros(0, self.dim, device=self.X.device)\n",
    "        \n",
    "        # ランダム方向の生成\n",
    "        num_rand = self.n_arms - num_coord\n",
    "        rand_arms = torch.randn(num_rand, self.dim, device=self.X.device) if num_rand > 0 else torch.zeros(0, self.dim, device=self.X.device)\n",
    "        \n",
    "        if num_rand > 0:\n",
    "            norms = rand_arms.norm(dim=1, keepdim=True)\n",
    "            rand_arms = torch.where(norms > 1e-9, rand_arms / norms, \n",
    "                                   torch.randn_like(rand_arms) / (torch.randn_like(rand_arms).norm(dim=1,keepdim=True)+1e-9))\n",
    "            \n",
    "        return torch.cat([coord_arms, rand_arms], 0)\n",
    "    \n",
    "    def select_arm(self, arms_features):\n",
    "        \"\"\"Linear UCBによる方向選択\"\"\"\n",
    "        # LinUCBパラメータ\n",
    "        sigma = 1.0\n",
    "        L = 1.0\n",
    "        lambda_reg = 1.0\n",
    "        delta = 0.1\n",
    "        S = 1.0\n",
    "        \n",
    "        # 現在のパラメータ推定\n",
    "        A_inv = torch.inverse(self.A)\n",
    "        theta = A_inv @ self.b\n",
    "        self.theta_history.append(theta.clone())\n",
    "        \n",
    "        # 信頼幅の計算\n",
    "        current_round_t = max(1, self.total_iterations)\n",
    "        log_term_numerator = max(1e-9, 1 + (current_round_t - 1) * L**2 / lambda_reg)\n",
    "        beta_t = (sigma * math.sqrt(self.dim * math.log(log_term_numerator / delta)) + \n",
    "                  math.sqrt(lambda_reg) * S)\n",
    "        \n",
    "        # UCBスコアの計算\n",
    "        ucb_scores = []\n",
    "        for i in range(arms_features.shape[0]):\n",
    "            x = arms_features[i].view(-1, 1)\n",
    "            mean = (theta.view(1, -1) @ x).item()\n",
    "            try:\n",
    "                var = (x.t() @ A_inv @ x).item()\n",
    "            except torch.linalg.LinAlgError:\n",
    "                var = (x.t() @ torch.linalg.pinv(self.A) @ x).item()\n",
    "                \n",
    "            ucb_scores.append(mean + beta_t * math.sqrt(max(var, 0)))\n",
    "            \n",
    "        return int(np.argmax(ucb_scores))\n",
    "    \n",
    "    def propose_new_x(self, direction):\n",
    "        \"\"\"選択された方向に沿った最適化\"\"\"\n",
    "        ei = ExpectedImprovement(self.model, best_f=self.best_value, maximize=False)\n",
    "        \n",
    "        # 方向に沿った探索範囲の計算\n",
    "        active_dims_mask = direction.abs() > 1e-9\n",
    "        if not active_dims_mask.any():\n",
    "            lb, ub = -1.0, 1.0\n",
    "        else:\n",
    "            ratios_lower = (self.bounds[0] - self.best_point) / (direction + 1e-12 * (~active_dims_mask))\n",
    "            ratios_upper = (self.bounds[1] - self.best_point) / (direction + 1e-12 * (~active_dims_mask))\n",
    "            \n",
    "            t_bounds = torch.zeros(self.dim, 2, device=self.X.device)\n",
    "            t_bounds[:, 0] = torch.minimum(ratios_lower, ratios_upper)\n",
    "            t_bounds[:, 1] = torch.maximum(ratios_lower, ratios_upper)\n",
    "            \n",
    "            lb = -float('inf')\n",
    "            ub = float('inf')\n",
    "            for i in range(self.dim):\n",
    "                if active_dims_mask[i]:\n",
    "                    lb = max(lb, t_bounds[i, 0].item())\n",
    "                    ub = min(ub, t_bounds[i, 1].item())\n",
    "                    \n",
    "        if lb > ub:\n",
    "            domain_width = (self.bounds[1, 0] - self.bounds[0, 0]).item()\n",
    "            lb = -0.1 * domain_width\n",
    "            ub = 0.1 * domain_width\n",
    "            \n",
    "        one_d_bounds = torch.tensor([[lb], [ub]], dtype=torch.float32, device=self.X.device)\n",
    "        \n",
    "        def ei_on_line(t_scalar_tensor):\n",
    "            t_values = t_scalar_tensor.squeeze(-1)\n",
    "            points_on_line = self.best_point.unsqueeze(0) + t_values.reshape(-1, 1) * direction.unsqueeze(0)\n",
    "            points_on_line_clamped = torch.clamp(points_on_line, self.bounds[0].unsqueeze(0), self.bounds[1].unsqueeze(0))\n",
    "            return ei(points_on_line_clamped.unsqueeze(1))\n",
    "        \n",
    "        # 獲得関数の最適化\n",
    "        cand_t, _ = optimize_acqf(\n",
    "            ei_on_line,\n",
    "            bounds=one_d_bounds,\n",
    "            q=1,\n",
    "            num_restarts=10,\n",
    "            raw_samples=100\n",
    "        )\n",
    "        \n",
    "        alpha_star = cand_t.item()\n",
    "        new_x = self.best_point + alpha_star * direction\n",
    "        new_x_clamped = torch.clamp(new_x, self.bounds[0], self.bounds[1])\n",
    "        \n",
    "        return new_x_clamped\n",
    "    \n",
    "    def optimize(self):\n",
    "        \"\"\"メインの最適化ループ\"\"\"\n",
    "        # 初期化\n",
    "        self.initialize()\n",
    "        n_iter = self.n_initial\n",
    "        \n",
    "        while n_iter < self.n_max:\n",
    "            self.total_iterations += 1\n",
    "            \n",
    "            # 探索方向の候補生成\n",
    "            arms_features = self.generate_arms()\n",
    "            \n",
    "            # Linear UCBによる方向選択\n",
    "            sel_idx = self.select_arm(arms_features)\n",
    "            direction = arms_features[sel_idx]\n",
    "            \n",
    "            # 選択された方向に沿った最適化\n",
    "            new_x = self.propose_new_x(direction)\n",
    "            \n",
    "            # 予測と実際の評価\n",
    "            with torch.no_grad():\n",
    "                predicted_mean = self.model.posterior(new_x.unsqueeze(0)).mean.squeeze().item()\n",
    "            actual_y = self.objective_function(new_x.unsqueeze(0)).squeeze().item()\n",
    "            \n",
    "            # 報酬の計算（勾配ベース + L_hatスケーリング）\n",
    "            new_x_for_grad = new_x.clone().unsqueeze(0)\n",
    "            new_x_for_grad.requires_grad_(True)\n",
    "            \n",
    "            # GPモデルで事後分布を取得\n",
    "            posterior = self.model.posterior(new_x_for_grad)\n",
    "            mean_at_new_x = posterior.mean\n",
    "            \n",
    "            # 勾配を計算\n",
    "            mean_at_new_x.sum().backward()\n",
    "            grad_vector = new_x_for_grad.grad.squeeze(0)\n",
    "            \n",
    "            # 報酬ベクトルを定義\n",
    "            reward_vector = grad_vector.abs()\n",
    "            \n",
    "            # 推定リプシッツ定数の更新\n",
    "            grad_norm = reward_vector.norm().item()\n",
    "            if grad_norm > self.L_hat:\n",
    "                self.L_hat = grad_norm\n",
    "            \n",
    "            # リプシッツ定数でスケーリング（スケーリングあり）\n",
    "            scaled_reward_vector = reward_vector / self.L_hat\n",
    "            \n",
    "            # Linear Banditパラメータの更新\n",
    "            x_arm = direction.view(-1, 1)\n",
    "            self.A += x_arm @ x_arm.t()\n",
    "            self.b += scaled_reward_vector\n",
    "            \n",
    "            # データとモデルの更新\n",
    "            self.X = torch.cat([self.X, new_x.unsqueeze(0)], 0)\n",
    "            self.Y = torch.cat([self.Y, torch.tensor([[actual_y]], dtype=torch.float32, device=self.X.device)], 0)\n",
    "            self.update_model()\n",
    "            \n",
    "            # 最良点の更新\n",
    "            with torch.no_grad():\n",
    "                posterior_mean = self.model.posterior(self.X).mean.squeeze(-1)\n",
    "            current_best_idx = posterior_mean.argmin()\n",
    "            self.best_value = posterior_mean[current_best_idx].item()\n",
    "            self.best_point = self.X[current_best_idx]\n",
    "            \n",
    "            self.eval_history.append(self.best_value)\n",
    "            n_iter += 1\n",
    "                \n",
    "        return self.best_point, self.best_value\n",
    "\n",
    "print(\"スケーリングあり版LinBandit-BOクラスの定義完了\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スケーリングあり版LinBandit-BOクラスの定義完了\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:11:18.174983Z",
     "start_time": "2025-07-22T04:11:18.143948Z"
    }
   },
   "source": "# スケーリングなし版LinBandit-BO（勾配ベース + 0.5x arms、スケーリングなし）\nclass GradientLinBanditBO_WithoutScaling:\n    \"\"\"\n    勾配報酬 + L_hatスケーリングなし版LinBandit-BO\n    \"\"\"\n    \n    def __init__(self, objective_function, bounds, n_initial=5, n_max=100, \n                 coordinate_ratio=0.8, n_arms=None):\n        self.objective_function = objective_function\n        self.bounds = bounds.float()\n        self.dim = bounds.shape[1]\n        self.n_initial = n_initial\n        self.n_max = n_max\n        self.coordinate_ratio = coordinate_ratio\n        \n        # 0.5x arms設定\n        self.n_arms = n_arms if n_arms is not None else max(1, self.dim // 2)\n        \n        # Linear Banditのパラメータ\n        self.A = torch.eye(self.dim)\n        self.b = torch.zeros(self.dim)\n        \n        # 初期点の生成\n        self.X = torch.rand(n_initial, self.dim) * (bounds[1] - bounds[0]) + bounds[0]\n        self.X = self.X.float()\n        \n        # 状態変数\n        self.Y = None\n        self.best_value = None\n        self.best_point = None\n        self.model = None\n        self.eval_history = []\n        self.theta_history = []\n        self.scale_init = 1.0\n        self.total_iterations = 0\n        \n        # 報酬履歴の記録\n        self.reward_history = []\n        \n    def update_model(self):\n        \"\"\"ガウス過程モデルの更新\"\"\"\n        kernel = ScaleKernel(\n            RBFKernel(ard_num_dims=self.X.shape[-1], dtype=torch.float32),\n            dtype=torch.float32, noise_constraint=1e-3\n        ).to(self.X)\n        self.model = SingleTaskGP(self.X, self.Y, covar_module=kernel)\n        mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)\n        fit_gpytorch_model(mll)\n        \n    def initialize(self):\n        \"\"\"初期化：初期点での評価とモデル構築\"\"\"\n        y_val = self.objective_function(self.X)\n        self.Y = y_val.unsqueeze(-1).float()\n        \n        # スケーリング係数の計算\n        y_max, y_min = self.Y.max().item(), self.Y.min().item()\n        self.scale_init = (y_max - y_min) if (y_max - y_min) != 0 else 1.0\n        \n        # モデルの初期化\n        self.update_model()\n        \n        # 最良点の初期化\n        post_mean = self.model.posterior(self.X).mean.squeeze(-1)\n        bi = post_mean.argmin()\n        self.best_value = post_mean[bi].item()\n        self.best_point = self.X[bi]\n        self.eval_history = [self.best_value] * self.n_initial\n        \n    def generate_arms(self):\n        \"\"\"アーム生成（0.5x arms）\"\"\"\n        num_coord = int(self.coordinate_ratio * self.n_arms)\n        num_coord = min(num_coord, self.dim)\n        \n        # ランダムに座標を選択\n        idxs = np.random.choice(self.dim, num_coord, replace=False)\n        \n        # 座標方向の生成\n        coords = []\n        for i in idxs:\n            e = torch.zeros(self.dim, device=self.X.device)\n            e[i] = 1.0\n            coords.append(e)\n            \n        coord_arms = torch.stack(coords, 0) if coords else torch.zeros(0, self.dim, device=self.X.device)\n        \n        # ランダム方向の生成\n        num_rand = self.n_arms - num_coord\n        rand_arms = torch.randn(num_rand, self.dim, device=self.X.device) if num_rand > 0 else torch.zeros(0, self.dim, device=self.X.device)\n        \n        if num_rand > 0:\n            norms = rand_arms.norm(dim=1, keepdim=True)\n            rand_arms = torch.where(norms > 1e-9, rand_arms / norms, \n                                   torch.randn_like(rand_arms) / (torch.randn_like(rand_arms).norm(dim=1,keepdim=True)+1e-9))\n            \n        return torch.cat([coord_arms, rand_arms], 0)\n    \n    def select_arm(self, arms_features):\n        \"\"\"Linear UCBによる方向選択\"\"\"\n        # LinUCBパラメータ\n        sigma = 1.0\n        L = 1.0\n        lambda_reg = 1.0\n        delta = 0.1\n        S = 1.0\n        \n        # 現在のパラメータ推定\n        A_inv = torch.inverse(self.A)\n        theta = A_inv @ self.b\n        self.theta_history.append(theta.clone())\n        \n        # 信頼幅の計算\n        current_round_t = max(1, self.total_iterations)\n        log_term_numerator = max(1e-9, 1 + (current_round_t - 1) * L**2 / lambda_reg)\n        beta_t = (sigma * math.sqrt(self.dim * math.log(log_term_numerator / delta)) + \n                  math.sqrt(lambda_reg) * S)\n        \n        # UCBスコアの計算\n        ucb_scores = []\n        for i in range(arms_features.shape[0]):\n            x = arms_features[i].view(-1, 1)\n            mean = (theta.view(1, -1) @ x).item()\n            try:\n                var = (x.t() @ A_inv @ x).item()\n            except torch.linalg.LinAlgError:\n                var = (x.t() @ torch.linalg.pinv(self.A) @ x).item()\n                \n            ucb_scores.append(mean + beta_t * math.sqrt(max(var, 0)))\n            \n        return int(np.argmax(ucb_scores))\n    \n    def propose_new_x(self, direction):\n        \"\"\"選択された方向に沿った最適化\"\"\"\n        ei = ExpectedImprovement(self.model, best_f=self.best_value, maximize=False)\n        \n        # 方向に沿った探索範囲の計算\n        active_dims_mask = direction.abs() > 1e-9\n        if not active_dims_mask.any():\n            lb, ub = -1.0, 1.0\n        else:\n            ratios_lower = (self.bounds[0] - self.best_point) / (direction + 1e-12 * (~active_dims_mask))\n            ratios_upper = (self.bounds[1] - self.best_point) / (direction + 1e-12 * (~active_dims_mask))\n            \n            t_bounds = torch.zeros(self.dim, 2, device=self.X.device)\n            t_bounds[:, 0] = torch.minimum(ratios_lower, ratios_upper)\n            t_bounds[:, 1] = torch.maximum(ratios_lower, ratios_upper)\n            \n            lb = -float('inf')\n            ub = float('inf')\n            for i in range(self.dim):\n                if active_dims_mask[i]:\n                    lb = max(lb, t_bounds[i, 0].item())\n                    ub = min(ub, t_bounds[i, 1].item())\n                    \n        if lb > ub:\n            domain_width = (self.bounds[1, 0] - self.bounds[0, 0]).item()\n            lb = -0.1 * domain_width\n            ub = 0.1 * domain_width\n            \n        one_d_bounds = torch.tensor([[lb], [ub]], dtype=torch.float32, device=self.X.device)\n        \n        def ei_on_line(t_scalar_tensor):\n            t_values = t_scalar_tensor.squeeze(-1)\n            points_on_line = self.best_point.unsqueeze(0) + t_values.reshape(-1, 1) * direction.unsqueeze(0)\n            points_on_line_clamped = torch.clamp(points_on_line, self.bounds[0].unsqueeze(0), self.bounds[1].unsqueeze(0))\n            return ei(points_on_line_clamped.unsqueeze(1))\n        \n        # 獲得関数の最適化\n        cand_t, _ = optimize_acqf(\n            ei_on_line,\n            bounds=one_d_bounds,\n            q=1,\n            num_restarts=10,\n            raw_samples=100\n        )\n        \n        alpha_star = cand_t.item()\n        new_x = self.best_point + alpha_star * direction\n        new_x_clamped = torch.clamp(new_x, self.bounds[0], self.bounds[1])\n        \n        return new_x_clamped\n    \n    def optimize(self):\n        \"\"\"メインの最適化ループ\"\"\"\n        # 初期化\n        self.initialize()\n        n_iter = self.n_initial\n        \n        while n_iter < self.n_max:\n            self.total_iterations += 1\n            \n            # 探索方向の候補生成\n            arms_features = self.generate_arms()\n            \n            # Linear UCBによる方向選択\n            sel_idx = self.select_arm(arms_features)\n            direction = arms_features[sel_idx]\n            \n            # 選択された方向に沿った最適化\n            new_x = self.propose_new_x(direction)\n            \n            # 予測と実際の評価\n            with torch.no_grad():\n                predicted_mean = self.model.posterior(new_x.unsqueeze(0)).mean.squeeze().item()\n            actual_y = self.objective_function(new_x.unsqueeze(0)).squeeze().item()\n            \n            # 報酬の計算（勾配ベース、スケーリングなし）\n            new_x_for_grad = new_x.clone().unsqueeze(0)\n            new_x_for_grad.requires_grad_(True)\n            \n            # GPモデルで事後分布を取得\n            posterior = self.model.posterior(new_x_for_grad)\n            mean_at_new_x = posterior.mean\n            \n            # 勾配を計算\n            mean_at_new_x.sum().backward()\n            grad_vector = new_x_for_grad.grad.squeeze(0)\n            \n            # 報酬ベクトルを定義（スケーリングなし）\n            reward_vector = grad_vector.abs()\n            \n            # 報酬を記録\n            self.reward_history.append(reward_vector.clone().detach().cpu().numpy())\n            \n            # Linear Banditパラメータの更新（スケーリングなし）\n            x_arm = direction.view(-1, 1)\n            self.A += x_arm @ x_arm.t()\n            self.b += reward_vector  # スケーリングしない\n            \n            # データとモデルの更新\n            self.X = torch.cat([self.X, new_x.unsqueeze(0)], 0)\n            self.Y = torch.cat([self.Y, torch.tensor([[actual_y]], dtype=torch.float32, device=self.X.device)], 0)\n            self.update_model()\n            \n            # 最良点の更新\n            with torch.no_grad():\n                posterior_mean = self.model.posterior(self.X).mean.squeeze(-1)\n            current_best_idx = posterior_mean.argmin()\n            self.best_value = posterior_mean[current_best_idx].item()\n            self.best_point = self.X[current_best_idx]\n            \n            self.eval_history.append(self.best_value)\n            n_iter += 1\n                \n        return self.best_point, self.best_value\n\nprint(\"スケーリングなし版LinBandit-BOクラスの定義完了\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:11:18.205518Z",
     "start_time": "2025-07-22T04:11:18.191010Z"
    }
   },
   "source": [
    "# テスト関数の定義\n",
    "def styblinski_tang_effective(x, effective_dims=5):\n",
    "    \"\"\"Styblinski-Tang関数（有効次元のみ）\"\"\"\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    \n",
    "    # 有効次元のみを使用\n",
    "    x_eff = x[..., :effective_dims]\n",
    "    return 0.5 * torch.sum(x_eff**4 - 16.0*x_eff**2 + 5.0*x_eff, dim=-1)\n",
    "\n",
    "def rastrigin_effective(x, effective_dims=5):\n",
    "    \"\"\"Rastrigin関数（有効次元のみ）\"\"\"\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    \n",
    "    # 有効次元のみを使用\n",
    "    x_eff = x[..., :effective_dims]\n",
    "    return torch.sum(x_eff**2 - 10.0*torch.cos(2*math.pi*x_eff) + 10.0, dim=-1)\n",
    "\n",
    "def ackley_effective(x, effective_dims=5):\n",
    "    \"\"\"Ackley関数（有効次元のみ）\"\"\"\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    \n",
    "    # 有効次元のみを使用\n",
    "    x_eff = x[..., :effective_dims]\n",
    "    d = x_eff.shape[-1]\n",
    "    \n",
    "    sum1 = torch.sum(x_eff**2, dim=-1)\n",
    "    sum2 = torch.sum(torch.cos(2*math.pi*x_eff), dim=-1)\n",
    "    \n",
    "    return -20.0 * torch.exp(-0.2 * torch.sqrt(sum1/d)) - torch.exp(sum2/d) + 20.0 + math.e\n",
    "\n",
    "# テスト関数の設定\n",
    "test_functions = {\n",
    "    'Styblinski-Tang': styblinski_tang_effective,\n",
    "    'Rastrigin': rastrigin_effective,\n",
    "    'Ackley': ackley_effective\n",
    "}\n",
    "\n",
    "# 大域的最適値\n",
    "global_optima = {\n",
    "    'Styblinski-Tang': -39.16599 * 5,  # 5次元\n",
    "    'Rastrigin': 0.0,\n",
    "    'Ackley': 0.0\n",
    "}\n",
    "\n",
    "print(\"テスト関数の定義完了\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テスト関数の定義完了\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:11:18.237050Z",
     "start_time": "2025-07-22T04:11:18.222537Z"
    }
   },
   "source": [
    "# 実験実行関数\n",
    "def run_single_experiment(algorithm_class, objective_function, bounds, algorithm_name):\n",
    "    \"\"\"単一実験の実行\"\"\"\n",
    "    optimizer = algorithm_class(\n",
    "        objective_function=objective_function,\n",
    "        bounds=bounds,\n",
    "        n_initial=5,\n",
    "        n_max=300,\n",
    "        coordinate_ratio=0.8\n",
    "    )\n",
    "    \n",
    "    # 同じ初期点を使用するため、シードを固定\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    optimizer.optimize()\n",
    "    \n",
    "    result = {\n",
    "        'eval_history': optimizer.eval_history,\n",
    "        'best_value': optimizer.best_value,\n",
    "        'theta_history': optimizer.theta_history\n",
    "    }\n",
    "    \n",
    "    # L_hat情報の追加\n",
    "    if hasattr(optimizer, 'L_hat'):\n",
    "        result['L_hat'] = optimizer.L_hat\n",
    "    elif hasattr(optimizer, 'L_hat_record'):\n",
    "        result['L_hat_record'] = optimizer.L_hat_record\n",
    "    \n",
    "    return result\n",
    "\n",
    "def run_comparison_experiment(func_name, objective_function, n_runs=20):\n",
    "    \"\"\"比較実験の実行\"\"\"\n",
    "    print(f\"\\n=== {func_name} 実験開始 ===\")\n",
    "    \n",
    "    dim = 20\n",
    "    bounds = torch.tensor([[-5.0]*dim, [5.0]*dim], dtype=torch.float32)\n",
    "    \n",
    "    results = {\n",
    "        'WithScaling': [],\n",
    "        'WithoutScaling': []\n",
    "    }\n",
    "    \n",
    "    algorithms = {\n",
    "        'WithScaling': GradientLinBanditBO_WithScaling,\n",
    "        'WithoutScaling': GradientLinBanditBO_WithoutScaling\n",
    "    }\n",
    "    \n",
    "    for alg_name, alg_class in algorithms.items():\n",
    "        print(f\"{alg_name}の実験中...\")\n",
    "        for run_idx in range(n_runs):\n",
    "            print(f\"\\r  実行中: {run_idx + 1}/{n_runs}\", end=\"\", flush=True)\n",
    "            \n",
    "            # 各実行で異なるシードを使用\n",
    "            torch.manual_seed(run_idx * 100)\n",
    "            np.random.seed(run_idx * 100)\n",
    "            \n",
    "            result = run_single_experiment(alg_class, objective_function, bounds, alg_name)\n",
    "            results[alg_name].append(result)\n",
    "        \n",
    "        print(f\"\\n  {alg_name}完了\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"実験実行関数の定義完了\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "実験実行関数の定義完了\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:11:18.268097Z",
     "start_time": "2025-07-22T04:11:18.253585Z"
    }
   },
   "source": "# 実験実行関数\ndef run_single_experiment(algorithm_class, objective_function, bounds, algorithm_name, fixed_L_hat=None):\n    \"\"\"単一実験の実行\"\"\"\n    if algorithm_name == \"WithScaling\" and fixed_L_hat is not None:\n        optimizer = algorithm_class(\n            objective_function=objective_function,\n            bounds=bounds,\n            n_initial=5,\n            n_max=300,\n            coordinate_ratio=0.8,\n            fixed_L_hat=fixed_L_hat\n        )\n    else:\n        optimizer = algorithm_class(\n            objective_function=objective_function,\n            bounds=bounds,\n            n_initial=5,\n            n_max=300,\n            coordinate_ratio=0.8\n        )\n    \n    # 同じ初期点を使用するため、シードを固定\n    torch.manual_seed(42)\n    np.random.seed(42)\n    \n    optimizer.optimize()\n    \n    result = {\n        'eval_history': optimizer.eval_history,\n        'best_value': optimizer.best_value,\n        'theta_history': optimizer.theta_history,\n        'reward_history': optimizer.reward_history\n    }\n    \n    # スケーリングされた報酬履歴も保存（スケーリングありの場合）\n    if hasattr(optimizer, 'scaled_reward_history'):\n        result['scaled_reward_history'] = optimizer.scaled_reward_history\n        result['L_hat'] = optimizer.L_hat\n    \n    return result\n\ndef run_comparison_experiment(func_name, objective_function, analytical_L_hat, n_runs=20):\n    \"\"\"比較実験の実行\"\"\"\n    print(f\"\\n=== {func_name} 実験開始 ===\")\n    print(f\"解析的L_hat: {analytical_L_hat:.2f}\")\n    \n    dim = 20\n    bounds = torch.tensor([[-5.0]*dim, [5.0]*dim], dtype=torch.float32)\n    \n    results = {\n        'WithScaling': [],\n        'WithoutScaling': []\n    }\n    \n    algorithms = {\n        'WithScaling': GradientLinBanditBO_WithFixedScaling,\n        'WithoutScaling': GradientLinBanditBO_WithoutScaling\n    }\n    \n    for alg_name, alg_class in algorithms.items():\n        print(f\"{alg_name}の実験中...\")\n        for run_idx in range(n_runs):\n            print(f\"\\r  実行中: {run_idx + 1}/{n_runs}\", end=\"\", flush=True)\n            \n            # 各実行で異なるシードを使用\n            torch.manual_seed(run_idx * 100)\n            np.random.seed(run_idx * 100)\n            \n            result = run_single_experiment(alg_class, objective_function, bounds, alg_name, analytical_L_hat)\n            results[alg_name].append(result)\n        \n        print(f\"\\n  {alg_name}完了\")\n    \n    return results\n\nprint(\"実験実行関数の定義完了\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:09:58.250775Z",
     "start_time": "2025-07-22T04:11:18.284127Z"
    }
   },
   "source": "# 報酬履歴の分析関数\ndef analyze_reward_history(results_dict, func_name):\n    \"\"\"報酬履歴の詳細分析とデータフレーム化\"\"\"\n    \n    # 各実行の報酬履歴を結合\n    reward_data = []\n    \n    for alg_name, results in results_dict.items():\n        for run_idx, result in enumerate(results):\n            reward_history = result['reward_history']\n            \n            # 各イテレーションの報酬を記録\n            for iter_idx, rewards in enumerate(reward_history):\n                for dim_idx, reward in enumerate(rewards):\n                    reward_data.append({\n                        'Algorithm': alg_name,\n                        'Run': run_idx,\n                        'Iteration': iter_idx + 5,  # n_initial=5を考慮\n                        'Dimension': dim_idx,\n                        'Reward': reward,\n                        'Scaled_Reward': result['scaled_reward_history'][iter_idx][dim_idx] if 'scaled_reward_history' in result else reward\n                    })\n    \n    # データフレーム化\n    df_rewards = pd.DataFrame(reward_data)\n    \n    # 各次元の平均報酬を計算\n    dim_rewards_summary = df_rewards.groupby(['Algorithm', 'Dimension'])['Reward'].agg(['mean', 'std', 'sum']).reset_index()\n    \n    # 可視化\n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    \n    # 1. 各次元の累積報酬（スケーリングなし）\n    ax1 = axes[0, 0]\n    without_scaling_data = dim_rewards_summary[dim_rewards_summary['Algorithm'] == 'WithoutScaling']\n    ax1.bar(without_scaling_data['Dimension'], without_scaling_data['sum'], color='red', alpha=0.7)\n    ax1.axvline(x=4.5, color='green', linestyle='--', label='Effective dims boundary')\n    ax1.set_xlabel('Dimension')\n    ax1.set_ylabel('Cumulative Reward')\n    ax1.set_title(f'{func_name}: 各次元の累積報酬（スケーリングなし）')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    # 2. 各次元の累積報酬（スケーリングあり）\n    ax2 = axes[0, 1]\n    with_scaling_data = dim_rewards_summary[dim_rewards_summary['Algorithm'] == 'WithScaling']\n    ax2.bar(with_scaling_data['Dimension'], with_scaling_data['sum'], color='blue', alpha=0.7)\n    ax2.axvline(x=4.5, color='green', linestyle='--', label='Effective dims boundary')\n    ax2.set_xlabel('Dimension')\n    ax2.set_ylabel('Cumulative Reward')\n    ax2.set_title(f'{func_name}: 各次元の累積報酬（スケーリングあり）')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    # 3. 報酬の時系列推移（有効次元の平均）\n    ax3 = axes[1, 0]\n    effective_dims = list(range(5))\n    \n    for alg_name in ['WithScaling', 'WithoutScaling']:\n        alg_data = df_rewards[df_rewards['Algorithm'] == alg_name]\n        effective_data = alg_data[alg_data['Dimension'].isin(effective_dims)]\n        \n        # イテレーションごとの有効次元の平均報酬\n        iter_mean_rewards = effective_data.groupby('Iteration')['Reward'].mean()\n        \n        color = 'blue' if alg_name == 'WithScaling' else 'red'\n        label = 'スケーリングあり' if alg_name == 'WithScaling' else 'スケーリングなし'\n        ax3.plot(iter_mean_rewards.index, iter_mean_rewards.values, color=color, label=label, alpha=0.7)\n    \n    ax3.set_xlabel('Iteration')\n    ax3.set_ylabel('Average Reward (Effective Dims)')\n    ax3.set_title(f'{func_name}: 有効次元の平均報酬推移')\n    ax3.legend()\n    ax3.grid(True, alpha=0.3)\n    \n    # 4. スケーリングの効果（スケーリングあり版のスケール前後比較）\n    ax4 = axes[1, 1]\n    if 'scaled_reward_history' in results_dict['WithScaling'][0]:\n        # スケーリング前後の報酬比較\n        scaled_data = df_rewards[df_rewards['Algorithm'] == 'WithScaling']\n        \n        # 各次元のスケーリング前後の平均報酬\n        dim_original = scaled_data.groupby('Dimension')['Reward'].mean()\n        dim_scaled = scaled_data.groupby('Dimension')['Scaled_Reward'].mean()\n        \n        x = np.arange(len(dim_original))\n        width = 0.35\n        \n        ax4.bar(x - width/2, dim_original.values, width, label='スケーリング前', color='orange', alpha=0.7)\n        ax4.bar(x + width/2, dim_scaled.values, width, label='スケーリング後', color='blue', alpha=0.7)\n        \n        ax4.axvline(x=4.5, color='green', linestyle='--', label='Effective dims boundary')\n        ax4.set_xlabel('Dimension')\n        ax4.set_ylabel('Average Reward')\n        ax4.set_title(f'{func_name}: スケーリング前後の報酬比較')\n        ax4.legend()\n        ax4.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(f'{output_dir}/{func_name}_reward_analysis.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    return df_rewards, dim_rewards_summary\n\nprint(\"報酬履歴分析関数の定義完了\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:09:58.314113Z",
     "start_time": "2025-07-22T10:09:58.299779Z"
    }
   },
   "source": "# 可視化関数\ndef plot_comparison_results(results_dict, func_name, global_optimum, analytical_L_hat):\n    \"\"\"比較結果の可視化\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    \n    # 1. 収束履歴の比較\n    ax1 = axes[0, 0]\n    colors = {'WithScaling': 'blue', 'WithoutScaling': 'red'}\n    labels = {'WithScaling': f'スケーリングあり (L_hat={analytical_L_hat:.1f})', 'WithoutScaling': 'スケーリングなし'}\n    \n    for alg_name, results in results_dict.items():\n        all_histories = [result['eval_history'] for result in results]\n        histories_array = np.array(all_histories)\n        \n        mean_history = np.mean(histories_array, axis=0)\n        std_history = np.std(histories_array, axis=0)\n        iterations = np.arange(1, len(mean_history) + 1)\n        \n        ax1.plot(iterations, mean_history, color=colors[alg_name], \n                label=f'{labels[alg_name]}', linewidth=2)\n        ax1.fill_between(iterations, mean_history - std_history, \n                        mean_history + std_history, color=colors[alg_name], alpha=0.2)\n    \n    ax1.axhline(y=global_optimum, color='green', linestyle='--', \n               label=f'Global optimum: {global_optimum:.2f}', linewidth=2)\n    ax1.set_xlabel('Iterations')\n    ax1.set_ylabel('Best Value Found')\n    ax1.set_title(f'{func_name}: 収束履歴比較')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    # 2. 最終性能の比較\n    ax2 = axes[0, 1]\n    final_values = {}\n    for alg_name, results in results_dict.items():\n        final_values[alg_name] = [result['best_value'] for result in results]\n    \n    box_data = [final_values['WithScaling'], final_values['WithoutScaling']]\n    box = ax2.boxplot(box_data, labels=['スケーリングあり', 'スケーリングなし'], patch_artist=True)\n    box['boxes'][0].set_facecolor('lightblue')\n    box['boxes'][1].set_facecolor('lightcoral')\n    \n    ax2.axhline(y=global_optimum, color='green', linestyle='--', \n               label=f'Global optimum: {global_optimum:.2f}', linewidth=2)\n    ax2.set_ylabel('Final Best Value')\n    ax2.set_title(f'{func_name}: 最終性能比較')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    # 3. 方向使用頻度の比較（スケーリングあり）\n    ax3 = axes[1, 0]\n    with_scaling_results = results_dict['WithScaling']\n    if with_scaling_results[0]['theta_history']:\n        all_final_theta = []\n        for result in with_scaling_results:\n            if result['theta_history']:\n                final_theta = result['theta_history'][-1].abs().cpu().numpy()\n                all_final_theta.append(final_theta)\n        \n        if all_final_theta:\n            mean_theta = np.mean(all_final_theta, axis=0)\n            std_theta = np.std(all_final_theta, axis=0)\n            \n            ax3.bar(range(len(mean_theta)), mean_theta, yerr=std_theta, \n                   capsize=5, color='lightblue', alpha=0.7)\n            ax3.axvline(x=4.5, color='red', linestyle='--', \n                       label='Effective dims boundary', linewidth=2)\n            ax3.set_xlabel('Dimension')\n            ax3.set_ylabel('Absolute Theta Value')\n            ax3.set_title(f'{func_name}: 方向使用頻度 (スケーリングあり)')\n            ax3.legend()\n            ax3.grid(True, alpha=0.3)\n    \n    # 4. 方向使用頻度の比較（スケーリングなし）\n    ax4 = axes[1, 1]\n    without_scaling_results = results_dict['WithoutScaling']\n    if without_scaling_results[0]['theta_history']:\n        all_final_theta = []\n        for result in without_scaling_results:\n            if result['theta_history']:\n                final_theta = result['theta_history'][-1].abs().cpu().numpy()\n                all_final_theta.append(final_theta)\n        \n        if all_final_theta:\n            mean_theta = np.mean(all_final_theta, axis=0)\n            std_theta = np.std(all_final_theta, axis=0)\n            \n            ax4.bar(range(len(mean_theta)), mean_theta, yerr=std_theta, \n                   capsize=5, color='lightcoral', alpha=0.7)\n            ax4.axvline(x=4.5, color='red', linestyle='--', \n                       label='Effective dims boundary', linewidth=2)\n            ax4.set_xlabel('Dimension')\n            ax4.set_ylabel('Absolute Theta Value')\n            ax4.set_title(f'{func_name}: 方向使用頻度 (スケーリングなし)')\n            ax4.legend()\n            ax4.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(f'{output_dir}/{func_name}_gradient_scaling_comparison.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    # 統計的要約の表示\n    print(f\"\\n=== {func_name} 結果要約 ===\")\n    for alg_name, results in results_dict.items():\n        final_values = [result['best_value'] for result in results]\n        label = 'スケーリングあり' if alg_name == 'WithScaling' else 'スケーリングなし'\n        print(f\"{label}:\")\n        print(f\"  平均: {np.mean(final_values):.6f}\")\n        print(f\"  標準偏差: {np.std(final_values):.6f}\")\n        print(f\"  最良値: {np.min(final_values):.6f}\")\n        print(f\"  最悪値: {np.max(final_values):.6f}\")\n\nprint(\"可視化関数の定義完了\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 実験の実行\nall_results = {}\nall_reward_dfs = {}\nn_runs = 20\n\n# 境界値\ndim = 20\nbounds = torch.tensor([[-5.0]*dim, [5.0]*dim], dtype=torch.float32)\n\nfor func_name, objective_function in test_functions.items():\n    print(f\"\\n{'='*50}\")\n    print(f\"実験: {func_name}\")\n    print(f\"{'='*50}\")\n    \n    # 解析的なL_hatを計算\n    analytical_L_hat = compute_analytical_max_gradient(func_name, bounds, effective_dims=5)\n    \n    # 実験実行\n    results = run_comparison_experiment(func_name, objective_function, analytical_L_hat, n_runs)\n    all_results[func_name] = results\n    \n    # 結果の保存\n    np.save(f'{output_dir}/{func_name}_gradient_scaling_results_fixed_L_hat.npy', results)\n    \n    # 基本的な可視化\n    plot_comparison_results(results, func_name, global_optima[func_name], analytical_L_hat)\n    \n    # 報酬履歴の詳細分析\n    df_rewards, dim_rewards_summary = analyze_reward_history(results, func_name)\n    all_reward_dfs[func_name] = df_rewards\n    \n    # データフレームをCSVとして保存\n    df_rewards.to_csv(f'{output_dir}/{func_name}_reward_history.csv', index=False)\n    dim_rewards_summary.to_csv(f'{output_dir}/{func_name}_dimension_rewards_summary.csv', index=False)\n    \n    print(f\"\\n報酬履歴をCSVファイルに保存しました\")\n\nprint(\"\\n全ての実験が完了しました！\")\nprint(f\"結果は {output_dir} フォルダに保存されています。\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 全体の比較サマリー\nprint(\"\\n\" + \"=\"*70)\nprint(\"全体結果サマリー: 固定L_hatスケーリングの効果検証\")\nprint(\"=\"*70)\nprint(\"両アルゴリズムの共通設定:\")\nprint(\"- 勾配ベース報酬（GPモデルの勾配の絶対値）\")\nprint(\"- 0.5x arms（次元数の半分のアーム数）\")\nprint(\"- coordinate_ratio=0.8\")\nprint(\"違い: 解析的に求めた固定L_hatによるスケーリングの有無\")\nprint(\"=\"*70)\n\nfor func_name in test_functions.keys():\n    results = all_results[func_name]\n    \n    with_scaling_final = [result['best_value'] for result in results['WithScaling']]\n    without_scaling_final = [result['best_value'] for result in results['WithoutScaling']]\n    \n    # 改善率の計算\n    with_scaling_mean = np.mean(with_scaling_final)\n    without_scaling_mean = np.mean(without_scaling_final)\n    improvement_rate = (without_scaling_mean - with_scaling_mean) / abs(without_scaling_mean) * 100\n    \n    # 解析的L_hatの取得\n    dim = 20\n    bounds = torch.tensor([[-5.0]*dim, [5.0]*dim], dtype=torch.float32)\n    analytical_L_hat = compute_analytical_max_gradient(func_name, bounds, effective_dims=5)\n    \n    print(f\"\\n{func_name}:\")\n    print(f\"  解析的L_hat: {analytical_L_hat:.2f}\")\n    print(f\"  スケーリングあり平均: {with_scaling_mean:.6f}\")\n    print(f\"  スケーリングなし平均: {without_scaling_mean:.6f}\")\n    print(f\"  スケーリングによる改善率: {improvement_rate:.2f}%\")\n    \n    # 統計的有意差の検定（Mann-Whitney U test）\n    from scipy.stats import mannwhitneyu\n    statistic, p_value = mannwhitneyu(with_scaling_final, without_scaling_final, alternative='two-sided')\n    print(f\"  統計的有意差 (p-value): {p_value:.4f}\")\n    \n    if p_value < 0.05:\n        if with_scaling_mean < without_scaling_mean:\n            print(f\"  → 固定スケーリングありが統計的に有意に優秀\")\n        else:\n            print(f\"  → スケーリングなしが統計的に有意に優秀\")\n    else:\n        print(f\"  → 統計的有意差なし\")\n    \n    # 報酬の統計情報\n    df = all_reward_dfs[func_name]\n    effective_dims_mask = df['Dimension'] < 5\n    \n    # 有効次元と非有効次元の報酬比較\n    effective_rewards = df[effective_dims_mask].groupby('Algorithm')['Reward'].mean()\n    non_effective_rewards = df[~effective_dims_mask].groupby('Algorithm')['Reward'].mean()\n    \n    print(f\"  有効次元平均報酬 (スケーリングあり): {effective_rewards.get('WithScaling', 0):.3f}\")\n    print(f\"  有効次元平均報酬 (スケーリングなし): {effective_rewards.get('WithoutScaling', 0):.3f}\")\n    print(f\"  非有効次元平均報酬 (スケーリングあり): {non_effective_rewards.get('WithScaling', 0):.3f}\")\n    print(f\"  非有効次元平均報酬 (スケーリングなし): {non_effective_rewards.get('WithoutScaling', 0):.3f}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"実験設定:\")\nprint(\"- 20次元問題（有効次元: 0-4）\")\nprint(\"- 各アルゴリズム20回独立実行\")\nprint(\"- 300回評価\")\nprint(\"- 固定L_hatスケーリング: 解析的に求めた最大勾配ノルムで正規化\")\nprint(\"- 報酬履歴をCSVファイルとして保存\")\nprint(\"=\"*70)",
   "metadata": {},
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}