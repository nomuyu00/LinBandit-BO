{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinBandit-BO リワード比較実験\n",
    "\n",
    "このノートブックでは、LinBandit-BOアルゴリズムについて、2つの異なるリワード設計を比較します：\n",
    "\n",
    "1. **元のリワード設計**: 予測誤差に基づくリワード計算\n",
    "2. **勾配ベースリワード設計**: GPモデルの勾配の絶対値を使ったリワード計算\n",
    "\n",
    "## 実験設定\n",
    "- アーム数: 次元数の0.5倍（20次元なら10本）に固定\n",
    "- coordinate_ratio = 0.8で固定\n",
    "- テスト関数: Styblinski-Tang, Rastrigin, Ackley (100次元中先頭5次元が有効)\n",
    "- 20回の独立実行\n",
    "- 300回の評価\n",
    "- 収束性能と方向選択の比較"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T05:30:31.826589Z",
     "start_time": "2025-07-17T05:30:31.806081Z"
    }
   },
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import torch\n",
    "\n",
    "# BoTorch / GPyTorch\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "# デフォルトのdtypeをfloat32に設定\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# プロット設定\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト関数群（100次元中先頭5次元が有効）"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T05:30:31.873589Z",
     "start_time": "2025-07-17T05:30:31.858590Z"
    }
   },
   "source": [
    "def styblinski_tang_100d(x, noise_std=1e-5):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    x5 = x[..., :5]\n",
    "    res = 0.5 * torch.sum(x5**4 - 16.0*x5**2 + 5.0*x5, dim=-1)\n",
    "    return res + torch.randn_like(res) * noise_std\n",
    "\n",
    "def rastrigin_100d(x, noise_std=1e-5):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    x5 = x[..., :5]\n",
    "    s = torch.sum(x5**2 - 10.0*torch.cos(2*math.pi*x5) + 10.0, dim=-1)\n",
    "    return s + torch.randn_like(s) * noise_std\n",
    "\n",
    "def ackley_100d(x, noise_std=1e-5):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    x5 = x[..., :5]\n",
    "    d = 5\n",
    "    sum_sq = torch.sum(x5**2, dim=-1)\n",
    "    r = torch.sqrt(sum_sq / d)\n",
    "    part1 = -20.0 * torch.exp(-0.2 * r)\n",
    "    part2 = -torch.exp(torch.mean(torch.cos(2.0*math.pi*x5), dim=-1))\n",
    "    res = part1 + part2 + 20.0 + math.e\n",
    "    return res + torch.randn_like(res) * noise_std"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinBandit-BO ベースクラス"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T05:30:32.060143Z",
     "start_time": "2025-07-17T05:30:31.889590Z"
    }
   },
   "source": [
    "class LinBanditBO_Base:\n",
    "    \"\"\"LinBandit-BO base class for reward comparison\"\"\"\n",
    "    \n",
    "    def __init__(self, X, objective_function, bounds, n_initial, n_max, dim,\n",
    "                 algo_base_name=\"LinBanditBO_Base\", coordinate_ratio=0.8, \n",
    "                 run_id=1, output_base_dir=\"output_results\", n_arms=None):\n",
    "        self.X = X.float()\n",
    "        self.dim = dim\n",
    "        self.n_arms = n_arms if n_arms is not None else dim\n",
    "        self.A = torch.eye(dim)\n",
    "        self.b = torch.zeros(dim)\n",
    "        self.objective_function = objective_function\n",
    "        self.bounds = bounds.float()\n",
    "        self.n_initial = n_initial\n",
    "        self.n_max = n_max\n",
    "        self.Y = None\n",
    "        self.best_value = None\n",
    "        self.best_point = None\n",
    "        self.model = None\n",
    "        self.eval_history = []\n",
    "        self.selected_direction_history = []\n",
    "        self.theta_history = []\n",
    "        self.coordinate_ratio = coordinate_ratio\n",
    "        self.scale_init = 1.0\n",
    "        self.run_id = run_id\n",
    "        self.total_iterations = 0\n",
    "        \n",
    "        # ファイル名設定\n",
    "        arms_ratio = self.n_arms / self.dim\n",
    "        self.function_name_with_ratio = f\"Arms_{arms_ratio:.1f}x_coord_{self.coordinate_ratio:.1f}\"\n",
    "        self.algo_name_for_run = f\"{algo_base_name}_{self.function_name_with_ratio}_run{self.run_id}\"\n",
    "        \n",
    "        self.output_dir = os.path.join(output_base_dir, algo_base_name, self.function_name_with_ratio)\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "    def update_model(self):\n",
    "        \"\"\"ガウス過程モデルの更新\"\"\"\n",
    "        kernel = ScaleKernel(\n",
    "            RBFKernel(ard_num_dims=self.X.shape[-1], dtype=torch.float32),\n",
    "            dtype=torch.float32, noise_constraint=1e-3\n",
    "        ).to(self.X)\n",
    "        self.model = SingleTaskGP(self.X, self.Y, covar_module=kernel)\n",
    "        mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)\n",
    "        fit_gpytorch_model(mll)\n",
    "        \n",
    "    def initialize(self):\n",
    "        \"\"\"初期化：初期点での評価とモデル構築\"\"\"\n",
    "        y_val = self.objective_function(self.X)\n",
    "        self.Y = y_val.unsqueeze(-1).float()\n",
    "        \n",
    "        # スケーリング係数の計算\n",
    "        y_max, y_min = self.Y.max().item(), self.Y.min().item()\n",
    "        self.scale_init = (y_max - y_min) if (y_max - y_min) != 0 else 1.0\n",
    "        \n",
    "        # モデルの初期化\n",
    "        self.update_model()\n",
    "        \n",
    "        # 最良点の初期化\n",
    "        post_mean = self.model.posterior(self.X).mean.squeeze(-1)\n",
    "        bi = post_mean.argmin()\n",
    "        self.best_value = post_mean[bi].item()\n",
    "        self.best_point = self.X[bi]\n",
    "        self.eval_history = [self.best_value] * self.n_initial\n",
    "        \n",
    "    def generate_arms(self):\n",
    "        \"\"\"アーム（方向ベクトル）を生成\"\"\"\n",
    "        num_coord = int(self.coordinate_ratio * self.n_arms)\n",
    "        num_coord = min(num_coord, self.dim)\n",
    "        \n",
    "        # 座標方向の生成\n",
    "        if num_coord > 0:\n",
    "            idxs = np.random.choice(self.dim, num_coord, replace=False)\n",
    "            \n",
    "            coords = []\n",
    "            for i in idxs:\n",
    "                e = torch.zeros(self.dim, device=self.X.device)\n",
    "                e[i] = 1.0\n",
    "                coords.append(e)\n",
    "                \n",
    "            coord_arms = torch.stack(coords, 0)\n",
    "        else:\n",
    "            coord_arms = torch.zeros(0, self.dim, device=self.X.device)\n",
    "        \n",
    "        # ランダム方向の生成\n",
    "        num_rand = self.n_arms - num_coord\n",
    "        if num_rand > 0:\n",
    "            rand_arms = torch.randn(num_rand, self.dim, device=self.X.device)\n",
    "            norms = rand_arms.norm(dim=1, keepdim=True)\n",
    "            rand_arms = torch.where(norms > 1e-9, rand_arms / norms, \n",
    "                                   torch.randn_like(rand_arms) / (torch.randn_like(rand_arms).norm(dim=1,keepdim=True)+1e-9))\n",
    "        else:\n",
    "            rand_arms = torch.zeros(0, self.dim, device=self.X.device)\n",
    "            \n",
    "        return torch.cat([coord_arms, rand_arms], 0)\n",
    "    \n",
    "    def select_arm(self, arms_features):\n",
    "        \"\"\"Linear UCBによる方向選択\"\"\"\n",
    "        # LinUCBパラメータ\n",
    "        sigma = 1.0\n",
    "        L = 1.0\n",
    "        lambda_reg = 1.0\n",
    "        delta = 0.1\n",
    "        S = 1.0\n",
    "        \n",
    "        # 現在のパラメータ推定\n",
    "        A_inv = torch.inverse(self.A)\n",
    "        theta = A_inv @ self.b\n",
    "        self.theta_history.append(theta.clone())\n",
    "        \n",
    "        # 信頼幅の計算\n",
    "        current_round_t = max(1, self.total_iterations)\n",
    "        log_term_numerator = max(1e-9, 1 + (current_round_t - 1) * L**2 / lambda_reg)\n",
    "        beta_t = (sigma * math.sqrt(self.dim * math.log(log_term_numerator / delta)) + \n",
    "                  math.sqrt(lambda_reg) * S)\n",
    "        \n",
    "        # UCBスコアの計算\n",
    "        ucb_scores = []\n",
    "        for i in range(arms_features.shape[0]):\n",
    "            x = arms_features[i].view(-1, 1)\n",
    "            mean = (theta.view(1, -1) @ x).item()\n",
    "            try:\n",
    "                var = (x.t() @ A_inv @ x).item()\n",
    "            except torch.linalg.LinAlgError:\n",
    "                var = (x.t() @ torch.linalg.pinv(self.A) @ x).item()\n",
    "                \n",
    "            ucb_scores.append(mean + beta_t * math.sqrt(max(var, 0)))\n",
    "            \n",
    "        return int(np.argmax(ucb_scores))\n",
    "    \n",
    "    def propose_new_x(self, direction):\n",
    "        \"\"\"選択された方向に沿った最適化\"\"\"\n",
    "        ei = ExpectedImprovement(self.model, best_f=self.best_value, maximize=False)\n",
    "        \n",
    "        # 方向に沿った探索範囲の計算\n",
    "        active_dims_mask = direction.abs() > 1e-9\n",
    "        if not active_dims_mask.any():\n",
    "            lb, ub = -1.0, 1.0\n",
    "        else:\n",
    "            ratios_lower = (self.bounds[0] - self.best_point) / (direction + 1e-12 * (~active_dims_mask))\n",
    "            ratios_upper = (self.bounds[1] - self.best_point) / (direction + 1e-12 * (~active_dims_mask))\n",
    "            \n",
    "            t_bounds = torch.zeros(self.dim, 2, device=self.X.device)\n",
    "            t_bounds[:, 0] = torch.minimum(ratios_lower, ratios_upper)\n",
    "            t_bounds[:, 1] = torch.maximum(ratios_lower, ratios_upper)\n",
    "            \n",
    "            lb = -float('inf')\n",
    "            ub = float('inf')\n",
    "            for i in range(self.dim):\n",
    "                if active_dims_mask[i]:\n",
    "                    lb = max(lb, t_bounds[i, 0].item())\n",
    "                    ub = min(ub, t_bounds[i, 1].item())\n",
    "                    \n",
    "        if lb > ub:\n",
    "            domain_width = (self.bounds[1, 0] - self.bounds[0, 0]).item()\n",
    "            lb = -0.1 * domain_width\n",
    "            ub = 0.1 * domain_width\n",
    "            \n",
    "        one_d_bounds = torch.tensor([[lb], [ub]], dtype=torch.float32, device=self.X.device)\n",
    "        \n",
    "        def ei_on_line(t_scalar_tensor):\n",
    "            t_values = t_scalar_tensor.squeeze(-1)\n",
    "            points_on_line = self.best_point.unsqueeze(0) + t_values.reshape(-1, 1) * direction.unsqueeze(0)\n",
    "            points_on_line_clamped = torch.clamp(points_on_line, self.bounds[0].unsqueeze(0), self.bounds[1].unsqueeze(0))\n",
    "            return ei(points_on_line_clamped.unsqueeze(1))\n",
    "        \n",
    "        # 獲得関数の最適化\n",
    "        cand_t, _ = optimize_acqf(\n",
    "            ei_on_line,\n",
    "            bounds=one_d_bounds,\n",
    "            q=1,\n",
    "            num_restarts=10,\n",
    "            raw_samples=100\n",
    "        )\n",
    "        \n",
    "        alpha_star = cand_t.item()\n",
    "        new_x = self.best_point + alpha_star * direction\n",
    "        new_x_clamped = torch.clamp(new_x, self.bounds[0], self.bounds[1])\n",
    "        \n",
    "        return new_x_clamped\n",
    "    \n",
    "    def calculate_reward(self, direction, new_x, predicted_mean, actual_y):\n",
    "        \"\"\"リワード計算（サブクラスでオーバーライド）\"\"\"\n",
    "        raise NotImplementedError(\"Subclass must implement calculate_reward method\")\n",
    "    \n",
    "    def optimize(self):\n",
    "        \"\"\"メインの最適化ループ\"\"\"\n",
    "        self.initialize()\n",
    "        n_iter = self.n_initial\n",
    "        \n",
    "        while n_iter < self.n_max:\n",
    "            self.total_iterations += 1\n",
    "            \n",
    "            # 探索方向の候補生成\n",
    "            arms_features = self.generate_arms()\n",
    "            \n",
    "            # Linear UCBによる方向選択\n",
    "            sel_idx = self.select_arm(arms_features)\n",
    "            direction = arms_features[sel_idx]\n",
    "            self.selected_direction_history.append(direction.clone())\n",
    "            \n",
    "            # 選択された方向に沿った最適化\n",
    "            new_x = self.propose_new_x(direction)\n",
    "            \n",
    "            # 予測と実際の評価\n",
    "            with torch.no_grad():\n",
    "                predicted_mean = self.model.posterior(new_x.unsqueeze(0)).mean.squeeze().item()\n",
    "            actual_y = self.objective_function(new_x.unsqueeze(0)).squeeze().item()\n",
    "            \n",
    "            # リワード計算（サブクラスで実装）\n",
    "            reward = self.calculate_reward(direction, new_x, predicted_mean, actual_y)\n",
    "            \n",
    "            # Linear Banditパラメータの更新\n",
    "            x_arm = direction.view(-1, 1)\n",
    "            self.A += x_arm @ x_arm.t()\n",
    "            self.b += reward\n",
    "            \n",
    "            # データとモデルの更新\n",
    "            self.X = torch.cat([self.X, new_x.unsqueeze(0)], 0)\n",
    "            self.Y = torch.cat([self.Y, torch.tensor([[actual_y]], dtype=torch.float32, device=self.X.device)], 0)\n",
    "            self.update_model()\n",
    "            \n",
    "            # 最良点の更新\n",
    "            with torch.no_grad():\n",
    "                posterior_mean = self.model.posterior(self.X).mean.squeeze(-1)\n",
    "            current_best_idx = posterior_mean.argmin()\n",
    "            self.best_value = posterior_mean[current_best_idx].item()\n",
    "            self.best_point = self.X[current_best_idx]\n",
    "            \n",
    "            self.eval_history.append(self.best_value)\n",
    "            n_iter += 1\n",
    "            \n",
    "        return self.best_point, self.best_value"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinBandit-BO：元のリワード設計（予測誤差ベース）"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T05:30:32.091143Z",
     "start_time": "2025-07-17T05:30:32.076143Z"
    }
   },
   "source": [
    "class LinBanditBO_Original(LinBanditBO_Base):\n",
    "    \"\"\"LinBandit-BO with original reward design (prediction error based)\"\"\"\n",
    "    \n",
    "    def __init__(self, X, objective_function, bounds, n_initial, n_max, dim,\n",
    "                 algo_base_name=\"LinBanditBO_Original\", coordinate_ratio=0.8, \n",
    "                 run_id=1, output_base_dir=\"output_results\", n_arms=None):\n",
    "        super().__init__(X, objective_function, bounds, n_initial, n_max, dim,\n",
    "                         algo_base_name, coordinate_ratio, run_id, output_base_dir, n_arms)\n",
    "    \n",
    "    def calculate_reward(self, direction, new_x, predicted_mean, actual_y):\n",
    "        \"\"\"元のリワード設計：予測誤差ベース\"\"\"\n",
    "        prediction_error = abs(predicted_mean - actual_y)\n",
    "        reward = 10.0 * (1.0 - math.exp(-prediction_error / self.scale_init))\n",
    "        return reward * direction"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinBandit-BO：勾配ベースリワード設計"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T05:30:32.121655Z",
     "start_time": "2025-07-17T05:30:32.106147Z"
    }
   },
   "source": [
    "class LinBanditBO_Gradient(LinBanditBO_Base):\n",
    "    \"\"\"LinBandit-BO with gradient-based reward design\"\"\"\n",
    "    \n",
    "    def __init__(self, X, objective_function, bounds, n_initial, n_max, dim,\n",
    "                 algo_base_name=\"LinBanditBO_Gradient\", coordinate_ratio=0.8, \n",
    "                 run_id=1, output_base_dir=\"output_results\", n_arms=None):\n",
    "        super().__init__(X, objective_function, bounds, n_initial, n_max, dim,\n",
    "                         algo_base_name, coordinate_ratio, run_id, output_base_dir, n_arms)\n",
    "    \n",
    "    def calculate_reward(self, direction, new_x, predicted_mean, actual_y):\n",
    "        \"\"\"勾配ベースリワード設計\"\"\"\n",
    "        # 勾配計算用の点を準備\n",
    "        new_x_for_grad = new_x.clone().unsqueeze(0)\n",
    "        new_x_for_grad.requires_grad_(True)\n",
    "        \n",
    "        # GPモデルで事後分布を取得\n",
    "        posterior = self.model.posterior(new_x_for_grad)\n",
    "        mean_at_new_x = posterior.mean\n",
    "        \n",
    "        # 勾配を計算\n",
    "        mean_at_new_x.sum().backward()\n",
    "        grad_vector = new_x_for_grad.grad.squeeze(0)\n",
    "        \n",
    "        # 報酬ベクトルを定義（絶対値を取ることで影響の大きさを評価）\n",
    "        reward_vector = grad_vector.abs()\n",
    "        \n",
    "        return reward_vector"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験実行"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T05:30:32.153655Z",
     "start_time": "2025-07-17T05:30:32.138656Z"
    }
   },
   "source": [
    "def generate_initial_points(n_initial, dim, bounds):\n",
    "    return torch.rand(n_initial, dim) * (bounds[1] - bounds[0]) + bounds[0]"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T05:35:54.726945Z",
     "start_time": "2025-07-17T05:30:32.169655Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_funcs = [\n",
    "        (\"StyblinskiTang\", styblinski_tang_100d, -195.83),\n",
    "        (\"Rastrigin\", rastrigin_100d, 0.0),\n",
    "        (\"Ackley\", ackley_100d, 0.0),\n",
    "    ]\n",
    "    dim = 20\n",
    "    bounds = torch.tensor([[-5.0]*dim, [5.0]*dim], dtype=torch.float32)\n",
    "    n_initial = 5\n",
    "    n_iter = 300  \n",
    "    n_runs = 20\n",
    "    \n",
    "    # アーム数を次元の0.5倍に設定\n",
    "    n_arms = dim // 2  # 20次元なら10本\n",
    "\n",
    "    output_base_dir = \"output_results_linbandit_reward_comparison\"\n",
    "    os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "    coordinate_ratio = 0.8\n",
    "\n",
    "    # 全実行で共通の初期点\n",
    "    initial_points_all_runs = [\n",
    "        generate_initial_points(n_initial, dim, bounds)\n",
    "        for _ in range(n_runs)\n",
    "    ]\n",
    "\n",
    "    algorithms = [\n",
    "        (\"Original_Reward\", LinBanditBO_Original),\n",
    "        (\"Gradient_Reward\", LinBanditBO_Gradient)\n",
    "    ]\n",
    "\n",
    "    for func_name_short, func_eval, global_opt_val in test_funcs:\n",
    "        print(f\"========== テスト関数実行中: {func_name_short} ==========\")\n",
    "\n",
    "        # 全アルゴリズムの結果を保存\n",
    "        all_algorithm_results = {}\n",
    "\n",
    "        for algo_name, algo_class in algorithms:\n",
    "            print(f\"--- {algo_name} アルゴリズム実行中 (アーム数: {n_arms}本) ---\")\n",
    "            \n",
    "            histories_for_this_algo = []\n",
    "            dim_sums_for_this_algo = []\n",
    "\n",
    "            # シンプルなプログレス表示\n",
    "            for run_idx in range(n_runs):\n",
    "                print(f\"\\r  実行中: {run_idx + 1}/{n_runs}\", end=\"\", flush=True)\n",
    "                \n",
    "                initial_X_for_run = initial_points_all_runs[run_idx].clone().to(dtype=torch.float32)\n",
    "\n",
    "                optimizer = algo_class(\n",
    "                    X=initial_X_for_run,\n",
    "                    objective_function=func_eval,\n",
    "                    bounds=bounds,\n",
    "                    n_initial=n_initial,\n",
    "                    n_max=n_iter,\n",
    "                    dim=dim,\n",
    "                    algo_base_name=func_name_short,\n",
    "                    coordinate_ratio=coordinate_ratio,\n",
    "                    run_id=run_idx + 1,\n",
    "                    output_base_dir=output_base_dir,\n",
    "                    n_arms=n_arms  # アーム数を0.5倍に設定\n",
    "                )\n",
    "\n",
    "                _, _ = optimizer.optimize()\n",
    "\n",
    "                histories_for_this_algo.append(optimizer.eval_history)\n",
    "\n",
    "                if optimizer.selected_direction_history:\n",
    "                    directions_tensor = torch.stack(optimizer.selected_direction_history, 0)\n",
    "                    abs_sum_per_dim = directions_tensor.abs().sum(dim=0).cpu().numpy()\n",
    "                    dim_sums_for_this_algo.append(abs_sum_per_dim)\n",
    "                else:\n",
    "                    dim_sums_for_this_algo.append(np.zeros(dim))\n",
    "            \n",
    "            print()  # 改行\n",
    "\n",
    "            # 収束統計の計算\n",
    "            eval_histories_np_array = np.array(histories_for_this_algo)\n",
    "            mean_convergence = eval_histories_np_array.mean(axis=0)\n",
    "            std_convergence = eval_histories_np_array.std(axis=0)\n",
    "\n",
    "            if dim_sums_for_this_algo:\n",
    "                avg_dim_abs_sum = np.mean(np.stack(dim_sums_for_this_algo, 0), axis=0)\n",
    "            else:\n",
    "                avg_dim_abs_sum = np.zeros(dim)\n",
    "\n",
    "            all_algorithm_results[algo_name] = {\n",
    "                'mean_hist': mean_convergence,\n",
    "                'std_hist': std_convergence,\n",
    "                'avg_dim_abs_sum': avg_dim_abs_sum\n",
    "            }\n",
    "\n",
    "            # 個別アルゴリズムの方向プロットを保存\n",
    "            plot_save_dir = os.path.join(output_base_dir, func_name_short, f\"{algo_name}_arms_{n_arms}_coord_{coordinate_ratio:.1f}\")\n",
    "            os.makedirs(plot_save_dir, exist_ok=True)\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.bar(np.arange(dim), avg_dim_abs_sum, alpha=0.7)\n",
    "            plt.xlabel(\"次元インデックス\", fontsize=12)\n",
    "            plt.ylabel(\"方向成分絶対値の平均和\", fontsize=12)\n",
    "            title_str = (f\"{func_name_short} - {algo_name} (アーム数: {n_arms}本)\\n\"\n",
    "                        f\"coord_ratio={coordinate_ratio:.1f}, {n_runs}回実行\")\n",
    "            plt.title(title_str, fontsize=14)\n",
    "            plt.xticks(np.arange(0, dim, step=max(1, dim//10)), fontsize=10)\n",
    "            plt.yticks(fontsize=10)\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(plot_save_dir, \"average_dimension_abs_sum.png\"), dpi=150)\n",
    "            plt.close()\n",
    "\n",
    "        # 比較収束プロットの作成\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        iters_plot = np.arange(1, n_iter + 1)\n",
    "        \n",
    "        colors = ['blue', 'red']\n",
    "        for i, (algo_name, results) in enumerate(all_algorithm_results.items()):\n",
    "            plt.plot(iters_plot, results['mean_hist'], \n",
    "                    label=f\"{algo_name}\", color=colors[i], linewidth=2)\n",
    "            plt.fill_between(iters_plot,\n",
    "                           results['mean_hist'] - results['std_hist'],\n",
    "                           results['mean_hist'] + results['std_hist'],\n",
    "                           alpha=0.2, color=colors[i])\n",
    "\n",
    "        plt.axhline(global_opt_val, color='green', linestyle='--', label='大域最適値', linewidth=2)\n",
    "        plt.xlabel(\"評価回数\", fontsize=14)\n",
    "        plt.ylabel(\"発見された最良目的値 (平均 ± 標準偏差)\", fontsize=14)\n",
    "        plt.title(f\"{func_name_short} - LinBandit-BO リワード比較\\n(アーム数: {n_arms}本, coordinate_ratio={coordinate_ratio:.1f})\", fontsize=16)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 比較プロットの保存\n",
    "        comparison_plot_save_dir = os.path.join(output_base_dir, func_name_short)\n",
    "        os.makedirs(comparison_plot_save_dir, exist_ok=True)\n",
    "        plt.savefig(os.path.join(comparison_plot_save_dir, f\"{func_name_short}_linbandit_reward_comparison.png\"), dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        # 方向比較プロットの作成\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        for i, (algo_name, results) in enumerate(all_algorithm_results.items()):\n",
    "            plt.subplot(1, 2, i+1)\n",
    "            plt.bar(np.arange(dim), results['avg_dim_abs_sum'], alpha=0.7, color=colors[i])\n",
    "            plt.xlabel(\"次元インデックス\", fontsize=10)\n",
    "            plt.ylabel(\"方向成分絶対値の平均和\", fontsize=10)\n",
    "            plt.title(f\"{algo_name}\\n{func_name_short} (アーム数: {n_arms}本)\", fontsize=12)\n",
    "            plt.xticks(np.arange(0, dim, step=max(1, dim//5)), fontsize=8)\n",
    "            plt.yticks(fontsize=8)\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "            \n",
    "        plt.suptitle(f\"LinBandit-BO リワード比較 - {func_name_short}\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(comparison_plot_save_dir, f\"{func_name_short}_direction_comparison.png\"), dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        # 最終性能の棒グラフ\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        algo_names_list = list(all_algorithm_results.keys())\n",
    "        final_means = [all_algorithm_results[name]['mean_hist'][-1] for name in algo_names_list]\n",
    "        final_stds = [all_algorithm_results[name]['std_hist'][-1] for name in algo_names_list]\n",
    "        x_pos = np.arange(len(algo_names_list))\n",
    "        \n",
    "        bars = plt.bar(x_pos, final_means, yerr=final_stds, capsize=10, \n",
    "                       color=colors[:len(algo_names_list)], alpha=0.7)\n",
    "        \n",
    "        plt.axhline(global_opt_val, color='black', linestyle='--', label='大域最適値', linewidth=2)\n",
    "        plt.xlabel(\"リワード設計\", fontsize=14)\n",
    "        plt.ylabel(\"最終的な最良値 (平均 ± 標準偏差)\", fontsize=14)\n",
    "        plt.title(f\"{func_name_short} - LinBandit-BO リワード比較\\n(アーム数: {n_arms}本)\", fontsize=16)\n",
    "        plt.xticks(x_pos, algo_names_list, fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(comparison_plot_save_dir, f\"{func_name_short}_final_performance.png\"), dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"========== テスト関数完了: {func_name_short} ==========\")\n",
    "\n",
    "    print(\"全ての実験が完了しました。\")\n",
    "    print(f\"アーム数設定: {n_arms}本 (次元数の0.5倍)\")\n",
    "    print(f\"coordinate_ratio: {coordinate_ratio}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== テスト関数実行中: StyblinskiTang ==========\n",
      "--- Original_Reward アルゴリズム実行中 (アーム数: 10本) ---\n",
      "  実行中: 2/20"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 62\u001B[0m\n\u001B[0;32m     46\u001B[0m initial_X_for_run \u001B[38;5;241m=\u001B[39m initial_points_all_runs[run_idx]\u001B[38;5;241m.\u001B[39mclone()\u001B[38;5;241m.\u001B[39mto(dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     48\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m algo_class(\n\u001B[0;32m     49\u001B[0m     X\u001B[38;5;241m=\u001B[39minitial_X_for_run,\n\u001B[0;32m     50\u001B[0m     objective_function\u001B[38;5;241m=\u001B[39mfunc_eval,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     59\u001B[0m     n_arms\u001B[38;5;241m=\u001B[39mn_arms  \u001B[38;5;66;03m# アーム数を0.5倍に設定\u001B[39;00m\n\u001B[0;32m     60\u001B[0m )\n\u001B[1;32m---> 62\u001B[0m _, _ \u001B[38;5;241m=\u001B[39m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     64\u001B[0m histories_for_this_algo\u001B[38;5;241m.\u001B[39mappend(optimizer\u001B[38;5;241m.\u001B[39meval_history)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m optimizer\u001B[38;5;241m.\u001B[39mselected_direction_history:\n",
      "Cell \u001B[1;32mIn[10], line 202\u001B[0m, in \u001B[0;36mLinBanditBO_Base.optimize\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mselected_direction_history\u001B[38;5;241m.\u001B[39mappend(direction\u001B[38;5;241m.\u001B[39mclone())\n\u001B[0;32m    201\u001B[0m \u001B[38;5;66;03m# 選択された方向に沿った最適化\u001B[39;00m\n\u001B[1;32m--> 202\u001B[0m new_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropose_new_x\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;66;03m# 予測と実際の評価\u001B[39;00m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "Cell \u001B[1;32mIn[10], line 167\u001B[0m, in \u001B[0;36mLinBanditBO_Base.propose_new_x\u001B[1;34m(self, direction)\u001B[0m\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ei(points_on_line_clamped\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m    166\u001B[0m \u001B[38;5;66;03m# 獲得関数の最適化\u001B[39;00m\n\u001B[1;32m--> 167\u001B[0m cand_t, _ \u001B[38;5;241m=\u001B[39m \u001B[43moptimize_acqf\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[43m    \u001B[49m\u001B[43mei_on_line\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    169\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mone_d_bounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    170\u001B[0m \u001B[43m    \u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    171\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_restarts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\n\u001B[0;32m    173\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m alpha_star \u001B[38;5;241m=\u001B[39m cand_t\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m    176\u001B[0m new_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_point \u001B[38;5;241m+\u001B[39m alpha_star \u001B[38;5;241m*\u001B[39m direction\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\botorch\\optim\\optimize.py:544\u001B[0m, in \u001B[0;36moptimize_acqf\u001B[1;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001B[0m\n\u001B[0;32m    521\u001B[0m     gen_candidates \u001B[38;5;241m=\u001B[39m gen_candidates_scipy\n\u001B[0;32m    522\u001B[0m opt_acqf_inputs \u001B[38;5;241m=\u001B[39m OptimizeAcqfInputs(\n\u001B[0;32m    523\u001B[0m     acq_function\u001B[38;5;241m=\u001B[39macq_function,\n\u001B[0;32m    524\u001B[0m     bounds\u001B[38;5;241m=\u001B[39mbounds,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    542\u001B[0m     ic_gen_kwargs\u001B[38;5;241m=\u001B[39mic_gen_kwargs,\n\u001B[0;32m    543\u001B[0m )\n\u001B[1;32m--> 544\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_optimize_acqf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopt_acqf_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\botorch\\optim\\optimize.py:573\u001B[0m, in \u001B[0;36m_optimize_acqf\u001B[1;34m(opt_inputs)\u001B[0m\n\u001B[0;32m    566\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _optimize_acqf_sequential_q(\n\u001B[0;32m    567\u001B[0m         opt_inputs\u001B[38;5;241m=\u001B[39mopt_inputs,\n\u001B[0;32m    568\u001B[0m         timeout_sec\u001B[38;5;241m=\u001B[39mtimeout_sec,\n\u001B[0;32m    569\u001B[0m         start_time\u001B[38;5;241m=\u001B[39mstart_time,\n\u001B[0;32m    570\u001B[0m     )\n\u001B[0;32m    572\u001B[0m \u001B[38;5;66;03m# Batch optimization (including the case q=1)\u001B[39;00m\n\u001B[1;32m--> 573\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_optimize_acqf_batch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    574\u001B[0m \u001B[43m    \u001B[49m\u001B[43mopt_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopt_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_time\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart_time\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout_sec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_sec\u001B[49m\n\u001B[0;32m    575\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\botorch\\optim\\optimize.py:351\u001B[0m, in \u001B[0;36m_optimize_acqf_batch\u001B[1;34m(opt_inputs, start_time, timeout_sec)\u001B[0m\n\u001B[0;32m    348\u001B[0m         batch_acq_values \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(batch_acq_values_list)\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[0;32m    349\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m batch_candidates, batch_acq_values, opt_warnings\n\u001B[1;32m--> 351\u001B[0m batch_candidates, batch_acq_values, ws \u001B[38;5;241m=\u001B[39m \u001B[43m_optimize_batch_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout_sec\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    353\u001B[0m optimization_warning_raised \u001B[38;5;241m=\u001B[39m \u001B[38;5;28many\u001B[39m(\n\u001B[0;32m    354\u001B[0m     (\u001B[38;5;28missubclass\u001B[39m(w\u001B[38;5;241m.\u001B[39mcategory, OptimizationWarning) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m ws)\n\u001B[0;32m    355\u001B[0m )\n\u001B[0;32m    356\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m optimization_warning_raised \u001B[38;5;129;01mand\u001B[39;00m opt_inputs\u001B[38;5;241m.\u001B[39mretry_on_optimization_warning:\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\botorch\\optim\\optimize.py:335\u001B[0m, in \u001B[0;36m_optimize_acqf_batch.<locals>._optimize_batch_candidates\u001B[1;34m(timeout_sec)\u001B[0m\n\u001B[0;32m    330\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings(record\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m ws:\n\u001B[0;32m    331\u001B[0m     warnings\u001B[38;5;241m.\u001B[39msimplefilter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malways\u001B[39m\u001B[38;5;124m\"\u001B[39m, category\u001B[38;5;241m=\u001B[39mOptimizationWarning)\n\u001B[0;32m    332\u001B[0m     (\n\u001B[0;32m    333\u001B[0m         batch_candidates_curr,\n\u001B[0;32m    334\u001B[0m         batch_acq_values_curr,\n\u001B[1;32m--> 335\u001B[0m     ) \u001B[38;5;241m=\u001B[39m opt_inputs\u001B[38;5;241m.\u001B[39mgen_candidates(\n\u001B[0;32m    336\u001B[0m         batched_ics_, opt_inputs\u001B[38;5;241m.\u001B[39macq_function, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfiltered_gen_kwargs\n\u001B[0;32m    337\u001B[0m     )\n\u001B[0;32m    338\u001B[0m opt_warnings \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m ws\n\u001B[0;32m    339\u001B[0m batch_candidates_list\u001B[38;5;241m.\u001B[39mappend(batch_candidates_curr)\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\botorch\\generation\\gen.py:232\u001B[0m, in \u001B[0;36mgen_candidates_scipy\u001B[1;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, options, fixed_features, timeout_sec)\u001B[0m\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mf\u001B[39m(x):\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39macquisition_function(x)\n\u001B[1;32m--> 232\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mminimize_with_timeout\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    233\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mf_np_wrapper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmethod\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSLSQP\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconstraints\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mL-BFGS-B\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    238\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconstraints\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconstraints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    240\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcallback\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    241\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[0;32m    242\u001B[0m \u001B[43m        \u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\n\u001B[0;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    244\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmethod\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcallback\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwith_grad\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m    245\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    246\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_sec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_sec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    247\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    248\u001B[0m _process_scipy_result(res\u001B[38;5;241m=\u001B[39mres, options\u001B[38;5;241m=\u001B[39moptions)\n\u001B[0;32m    250\u001B[0m candidates \u001B[38;5;241m=\u001B[39m fix_features(\n\u001B[0;32m    251\u001B[0m     X\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfrom_numpy(res\u001B[38;5;241m.\u001B[39mx)\u001B[38;5;241m.\u001B[39mto(initial_conditions)\u001B[38;5;241m.\u001B[39mreshape(shapeX),\n\u001B[0;32m    252\u001B[0m     fixed_features\u001B[38;5;241m=\u001B[39mfixed_features,\n\u001B[0;32m    253\u001B[0m )\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\botorch\\optim\\utils\\timeout.py:80\u001B[0m, in \u001B[0;36mminimize_with_timeout\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001B[0m\n\u001B[0;32m     77\u001B[0m     wrapped_callback \u001B[38;5;241m=\u001B[39m callback\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 80\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moptimize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     85\u001B[0m \u001B[43m        \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhess\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhessp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhessp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconstraints\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconstraints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     91\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwrapped_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m OptimizationTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     95\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimization timed out after \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;241m.\u001B[39mruntime\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:713\u001B[0m, in \u001B[0;36mminimize\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[0;32m    710\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[0;32m    711\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    712\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml-bfgs-b\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 713\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001B[0;32m    714\u001B[0m                            callback\u001B[38;5;241m=\u001B[39mcallback, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    715\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtnc\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    716\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[0;32m    717\u001B[0m                         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001B[0m, in \u001B[0;36m_minimize_lbfgsb\u001B[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001B[0m\n\u001B[0;32m    401\u001B[0m task_str \u001B[38;5;241m=\u001B[39m task\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFG\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    403\u001B[0m     \u001B[38;5;66;03m# The minimization routine wants f and g at the current x.\u001B[39;00m\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001B[39;00m\n\u001B[0;32m    405\u001B[0m     \u001B[38;5;66;03m# until the completion of the current minimization iteration.\u001B[39;00m\n\u001B[0;32m    406\u001B[0m     \u001B[38;5;66;03m# Overwrite f and g:\u001B[39;00m\n\u001B[1;32m--> 407\u001B[0m     f, g \u001B[38;5;241m=\u001B[39m \u001B[43mfunc_and_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNEW_X\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    409\u001B[0m     \u001B[38;5;66;03m# new iteration\u001B[39;00m\n\u001B[0;32m    410\u001B[0m     n_iterations \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:296\u001B[0m, in \u001B[0;36mScalarFunction.fun_and_grad\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray_equal(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx):\n\u001B[0;32m    295\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_x_impl(x)\n\u001B[1;32m--> 296\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    297\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_grad()\n\u001B[0;32m    298\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:262\u001B[0m, in \u001B[0;36mScalarFunction._update_fun\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_update_fun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated:\n\u001B[1;32m--> 262\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    263\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:163\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.update_fun\u001B[1;34m()\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mupdate_fun\u001B[39m():\n\u001B[1;32m--> 163\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[43mfun_wrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:145\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnfev \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;66;03m# Send a copy because the user may overwrite it.\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;66;03m# Overwriting results in undefined behaviour because\u001B[39;00m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001B[39;00m\n\u001B[1;32m--> 145\u001B[0m fx \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;66;03m# Make sure the function returns a true scalar\u001B[39;00m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(fx):\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\scipy\\optimize\\_optimize.py:79\u001B[0m, in \u001B[0;36mMemoizeJac.__call__\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m     78\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" returns the function value \"\"\"\u001B[39;00m\n\u001B[1;32m---> 79\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_if_needed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\scipy\\optimize\\_optimize.py:73\u001B[0m, in \u001B[0;36mMemoizeJac._compute_if_needed\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(x \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m---> 73\u001B[0m     fg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\botorch\\generation\\gen.py:192\u001B[0m, in \u001B[0;36mgen_candidates_scipy.<locals>.f_np_wrapper\u001B[1;34m(x, f)\u001B[0m\n\u001B[0;32m    190\u001B[0m loss \u001B[38;5;241m=\u001B[39m f(X_fix)\u001B[38;5;241m.\u001B[39msum()\n\u001B[0;32m    191\u001B[0m \u001B[38;5;66;03m# compute gradient w.r.t. the inputs (does not accumulate in leaves)\u001B[39;00m\n\u001B[1;32m--> 192\u001B[0m gradf \u001B[38;5;241m=\u001B[39m _arrayify(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mcontiguous()\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39misnan(gradf)\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m    194\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    195\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnp\u001B[38;5;241m.\u001B[39misnan(gradf)\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m elements of the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39msize\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m element \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    196\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgradient array `gradf` are NaN. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    197\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis often indicates numerical issues.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    198\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:502\u001B[0m, in \u001B[0;36mgrad\u001B[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001B[0m\n\u001B[0;32m    498\u001B[0m     result \u001B[38;5;241m=\u001B[39m _vmap_internals\u001B[38;5;241m.\u001B[39m_vmap(vjp, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, allow_none_pass_through\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)(\n\u001B[0;32m    499\u001B[0m         grad_outputs_\n\u001B[0;32m    500\u001B[0m     )\n\u001B[0;32m    501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 502\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_outputs_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_unused\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    509\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m materialize_grads:\n\u001B[0;32m    512\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\n\u001B[0;32m    513\u001B[0m         result[i] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_tensor_like(inputs[i])\n\u001B[0;32m    514\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(inputs))\n\u001B[0;32m    515\u001B[0m     ):\n",
      "File \u001B[1;32m~\\PycharmProjects\\LinBandit-BO\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    822\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    823\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 824\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    825\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    826\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    827\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    828\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果の分析と考察\n",
    "\n",
    "実験完了後、以下の観点から分析を行います：\n",
    "\n",
    "### 1. リワード設計の違いによる影響\n",
    "- **元のリワード**: 予測誤差に基づく単一のスカラー値でbanditパラメータを更新\n",
    "- **勾配ベースリワード**: GPモデルの勾配ベクトルの絶対値で各次元を個別に更新\n",
    "\n",
    "### 2. 収束性能の比較\n",
    "- どちらのリワード設計が faster convergence を示すか\n",
    "- 最終的な最適化性能の差\n",
    "\n",
    "### 3. 方向選択の特性\n",
    "- 勾配ベースリワードが有効次元（0-4）により効率的に集中するか\n",
    "- 各次元の使用頻度の違い\n",
    "\n",
    "### 4. アーム数設定の影響\n",
    "- 次元数の0.5倍（10本）のアーム数設定での効果\n",
    "- 計算効率とのトレードオフ\n",
    "\n",
    "### 5. テスト関数による違い\n",
    "- 関数の特性（滑らかさ、多峰性）によるリワード設計の効果の違い\n",
    "- Styblinski-Tang, Rastrigin, Ackley での性能比較\n",
    "\n",
    "実験を実行して、これらの観点から結果を確認してください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
