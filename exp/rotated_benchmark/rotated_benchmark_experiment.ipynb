{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験2A：回転したベンチマーク関数での頑健性評価\n",
    "\n",
    "この実験では、LinBandit-BOの汎用性と頑健性を示すため、回転したベンチマーク関数での性能を評価します。\n",
    "\n",
    "## 目的：\n",
    "- 「軸に沿った問題でしか機能しないのでは？」という懸念を払拭\n",
    "- 非軸並行な低次元構造を持つ問題での性能を検証\n",
    "\n",
    "## 方法：\n",
    "- 元のベンチマーク関数 f(x) を f(Qx) に変更（Qはランダム正規直交行列）\n",
    "- これにより、有効な低次元部分空間が座標軸と無関係になる\n",
    "\n",
    "## 比較対象：\n",
    "1. LinBandit-BO\n",
    "2. TuRBO\n",
    "3. ALEBO\n",
    "4. Vanilla BO\n",
    "5. Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# BoTorch imports\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from botorch.acquisition import ExpectedImprovement, UpperConfidenceBound\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.utils.transforms import normalize, unnormalize\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "# デフォルトのdtypeをfloat32に設定\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# プロット設定\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# 日本語フォント設定\n",
    "try:\n",
    "    import japanize_matplotlib\n",
    "except ImportError:\n",
    "    import matplotlib\n",
    "    if os.name == 'nt':\n",
    "        plt.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo']\n",
    "    elif os.uname().sysname == 'Darwin':\n",
    "        plt.rcParams['font.family'] = ['Hiragino Sans', 'Hiragino Maru Gothic Pro']\n",
    "    else:\n",
    "        plt.rcParams['font.family'] = ['IPAGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP', 'TakaoGothic']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 出力フォルダの作成\n",
    "output_dir = \"output_results_rotated_benchmark\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"実験環境の設定完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回転行列の生成\n",
    "def generate_rotation_matrix(dim, seed=None):\n",
    "    \"\"\"ランダムな正規直交行列（回転行列）を生成\"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    # ランダム行列を生成\n",
    "    A = torch.randn(dim, dim)\n",
    "    \n",
    "    # QR分解で正規直交行列を取得\n",
    "    Q, R = torch.linalg.qr(A)\n",
    "    \n",
    "    # 行列式が正であることを確認（回転行列にする）\n",
    "    if torch.det(Q) < 0:\n",
    "        Q[:, 0] = -Q[:, 0]\n",
    "    \n",
    "    return Q\n",
    "\n",
    "# 回転したテスト関数の作成\n",
    "def create_rotated_function(base_function, rotation_matrix):\n",
    "    \"\"\"元の関数を回転させた新しい関数を作成\"\"\"\n",
    "    def rotated_function(x):\n",
    "        # 入力を回転\n",
    "        if x.dim() == 1:\n",
    "            x_rotated = rotation_matrix @ x\n",
    "        else:\n",
    "            x_rotated = x @ rotation_matrix.T\n",
    "        \n",
    "        # 回転した座標で元の関数を評価\n",
    "        return base_function(x_rotated)\n",
    "    \n",
    "    return rotated_function\n",
    "\n",
    "print(\"回転行列生成関数の定義完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験1で使用したアルゴリズムクラスをコピー（LinBandit-BO）\n",
    "class LinBanditBO:\n",
    "    def __init__(self, objective_function, bounds, n_initial=5, n_max=100, \n",
    "                 coordinate_ratio=0.8, n_arms=None):\n",
    "        self.objective_function = objective_function\n",
    "        self.bounds = bounds.float()\n",
    "        self.dim = bounds.shape[1]\n",
    "        self.n_initial = n_initial\n",
    "        self.n_max = n_max\n",
    "        self.coordinate_ratio = coordinate_ratio\n",
    "        \n",
    "        # 0.5x arms設定\n",
    "        self.n_arms = n_arms if n_arms is not None else max(1, self.dim // 2)\n",
    "        \n",
    "        # Linear Banditのパラメータ\n",
    "        self.A = torch.eye(self.dim)\n",
    "        self.b = torch.zeros(self.dim)\n",
    "        \n",
    "        # 初期点の生成\n",
    "        self.X = torch.rand(n_initial, self.dim) * (bounds[1] - bounds[0]) + bounds[0]\n",
    "        self.X = self.X.float()\n",
    "        \n",
    "        # 状態変数\n",
    "        self.Y = None\n",
    "        self.best_value = None\n",
    "        self.best_point = None\n",
    "        self.model = None\n",
    "        self.eval_history = []\n",
    "        self.theta_history = []\n",
    "        self.scale_init = 1.0\n",
    "        self.total_iterations = 0\n",
    "        \n",
    "    def update_model(self):\n",
    "        kernel = ScaleKernel(\n",
    "            RBFKernel(ard_num_dims=self.X.shape[-1], dtype=torch.float32),\n",
    "            dtype=torch.float32\n",
    "        ).to(self.X)\n",
    "        self.model = SingleTaskGP(self.X, self.Y, covar_module=kernel)\n",
    "        mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)\n",
    "        fit_gpytorch_model(mll)\n",
    "        \n",
    "    def initialize(self):\n",
    "        y_val = self.objective_function(self.X)\n",
    "        self.Y = y_val.unsqueeze(-1).float()\n",
    "        \n",
    "        y_max, y_min = self.Y.max().item(), self.Y.min().item()\n",
    "        self.scale_init = (y_max - y_min) if (y_max - y_min) != 0 else 1.0\n",
    "        \n",
    "        self.update_model()\n",
    "        \n",
    "        post_mean = self.model.posterior(self.X).mean.squeeze(-1)\n",
    "        bi = post_mean.argmin()\n",
    "        self.best_value = post_mean[bi].item()\n",
    "        self.best_point = self.X[bi]\n",
    "        self.eval_history = [self.best_value] * self.n_initial\n",
    "        \n",
    "    def generate_arms(self):\n",
    "        num_coord = int(self.coordinate_ratio * self.n_arms)\n",
    "        num_coord = min(num_coord, self.dim)\n",
    "        \n",
    "        idxs = np.random.choice(self.dim, num_coord, replace=False)\n",
    "        \n",
    "        coords = []\n",
    "        for i in idxs:\n",
    "            e = torch.zeros(self.dim, device=self.X.device)\n",
    "            e[i] = 1.0\n",
    "            coords.append(e)\n",
    "            \n",
    "        coord_arms = torch.stack(coords, 0) if coords else torch.zeros(0, self.dim, device=self.X.device)\n",
    "        \n",
    "        num_rand = self.n_arms - num_coord\n",
    "        rand_arms = torch.randn(num_rand, self.dim, device=self.X.device) if num_rand > 0 else torch.zeros(0, self.dim, device=self.X.device)\n",
    "        \n",
    "        if num_rand > 0:\n",
    "            norms = rand_arms.norm(dim=1, keepdim=True)\n",
    "            rand_arms = torch.where(norms > 1e-9, rand_arms / norms, \n",
    "                                   torch.randn_like(rand_arms) / (torch.randn_like(rand_arms).norm(dim=1,keepdim=True)+1e-9))\n",
    "            \n",
    "        return torch.cat([coord_arms, rand_arms], 0)\n",
    "    \n",
    "    def select_arm(self, arms_features):\n",
    "        sigma = 1.0\n",
    "        L = 1.0\n",
    "        lambda_reg = 1.0\n",
    "        delta = 0.1\n",
    "        S = 1.0\n",
    "        \n",
    "        A_inv = torch.inverse(self.A)\n",
    "        theta = A_inv @ self.b\n",
    "        self.theta_history.append(theta.clone())\n",
    "        \n",
    "        current_round_t = max(1, self.total_iterations)\n",
    "        log_term_numerator = max(1e-9, 1 + (current_round_t - 1) * L**2 / lambda_reg)\n",
    "        beta_t = (sigma * math.sqrt(self.dim * math.log(log_term_numerator / delta)) + \n",
    "                  math.sqrt(lambda_reg) * S)\n",
    "        \n",
    "        ucb_scores = []\n",
    "        for i in range(arms_features.shape[0]):\n",
    "            x = arms_features[i].view(-1, 1)\n",
    "            mean = (theta.view(1, -1) @ x).item()\n",
    "            try:\n",
    "                var = (x.t() @ A_inv @ x).item()\n",
    "            except torch.linalg.LinAlgError:\n",
    "                var = (x.t() @ torch.linalg.pinv(self.A) @ x).item()\n",
    "                \n",
    "            ucb_scores.append(mean + beta_t * math.sqrt(max(var, 0)))\n",
    "            \n",
    "        return int(np.argmax(ucb_scores))\n",
    "    \n",
    "    def propose_new_x(self, direction):\n",
    "        ei = ExpectedImprovement(self.model, best_f=self.best_value, maximize=False)\n",
    "        \n",
    "        active_dims_mask = direction.abs() > 1e-9\n",
    "        if not active_dims_mask.any():\n",
    "            lb, ub = -1.0, 1.0\n",
    "        else:\n",
    "            ratios_lower = (self.bounds[0] - self.best_point) / (direction + 1e-12 * (~active_dims_mask))\n",
    "            ratios_upper = (self.bounds[1] - self.best_point) / (direction + 1e-12 * (~active_dims_mask))\n",
    "            \n",
    "            t_bounds = torch.zeros(self.dim, 2, device=self.X.device)\n",
    "            t_bounds[:, 0] = torch.minimum(ratios_lower, ratios_upper)\n",
    "            t_bounds[:, 1] = torch.maximum(ratios_lower, ratios_upper)\n",
    "            \n",
    "            lb = -float('inf')\n",
    "            ub = float('inf')\n",
    "            for i in range(self.dim):\n",
    "                if active_dims_mask[i]:\n",
    "                    lb = max(lb, t_bounds[i, 0].item())\n",
    "                    ub = min(ub, t_bounds[i, 1].item())\n",
    "                    \n",
    "        if lb > ub:\n",
    "            domain_width = (self.bounds[1, 0] - self.bounds[0, 0]).item()\n",
    "            lb = -0.1 * domain_width\n",
    "            ub = 0.1 * domain_width\n",
    "            \n",
    "        one_d_bounds = torch.tensor([[lb], [ub]], dtype=torch.float32, device=self.X.device)\n",
    "        \n",
    "        def ei_on_line(t_scalar_tensor):\n",
    "            t_values = t_scalar_tensor.squeeze(-1)\n",
    "            points_on_line = self.best_point.unsqueeze(0) + t_values.reshape(-1, 1) * direction.unsqueeze(0)\n",
    "            points_on_line_clamped = torch.clamp(points_on_line, self.bounds[0].unsqueeze(0), self.bounds[1].unsqueeze(0))\n",
    "            return ei(points_on_line_clamped.unsqueeze(1))\n",
    "        \n",
    "        cand_t, _ = optimize_acqf(\n",
    "            ei_on_line,\n",
    "            bounds=one_d_bounds,\n",
    "            q=1,\n",
    "            num_restarts=10,\n",
    "            raw_samples=100\n",
    "        )\n",
    "        \n",
    "        alpha_star = cand_t.item()\n",
    "        new_x = self.best_point + alpha_star * direction\n",
    "        new_x_clamped = torch.clamp(new_x, self.bounds[0], self.bounds[1])\n",
    "        \n",
    "        return new_x_clamped\n",
    "    \n",
    "    def optimize(self):\n",
    "        self.initialize()\n",
    "        n_iter = self.n_initial\n",
    "        \n",
    "        while n_iter < self.n_max:\n",
    "            self.total_iterations += 1\n",
    "            \n",
    "            arms_features = self.generate_arms()\n",
    "            sel_idx = self.select_arm(arms_features)\n",
    "            direction = arms_features[sel_idx]\n",
    "            \n",
    "            new_x = self.propose_new_x(direction)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predicted_mean = self.model.posterior(new_x.unsqueeze(0)).mean.squeeze().item()\n",
    "            actual_y = self.objective_function(new_x.unsqueeze(0)).squeeze().item()\n",
    "            \n",
    "            # 勾配ベース報酬\n",
    "            new_x_for_grad = new_x.clone().unsqueeze(0)\n",
    "            new_x_for_grad.requires_grad_(True)\n",
    "            \n",
    "            posterior = self.model.posterior(new_x_for_grad)\n",
    "            mean_at_new_x = posterior.mean\n",
    "            \n",
    "            mean_at_new_x.sum().backward()\n",
    "            grad_vector = new_x_for_grad.grad.squeeze(0)\n",
    "            \n",
    "            reward_vector = grad_vector.abs()\n",
    "            \n",
    "            x_arm = direction.view(-1, 1)\n",
    "            self.A += x_arm @ x_arm.t()\n",
    "            self.b += reward_vector\n",
    "            \n",
    "            self.X = torch.cat([self.X, new_x.unsqueeze(0)], 0)\n",
    "            self.Y = torch.cat([self.Y, torch.tensor([[actual_y]], dtype=torch.float32, device=self.X.device)], 0)\n",
    "            self.update_model()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                posterior_mean = self.model.posterior(self.X).mean.squeeze(-1)\n",
    "            current_best_idx = posterior_mean.argmin()\n",
    "            self.best_value = posterior_mean[current_best_idx].item()\n",
    "            self.best_point = self.X[current_best_idx]\n",
    "            \n",
    "            self.eval_history.append(self.best_value)\n",
    "            n_iter += 1\n",
    "                \n",
    "        return self.best_point, self.best_value\n",
    "\n",
    "print(\"LinBandit-BOクラスの定義完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 他のアルゴリズムも同様にコピー（TuRBO、ALEBO、Vanilla BO、Random Search）\n",
    "# （実験1と同じコードなので、スペースの都合上省略しますが、実際の実装では含めます）\n",
    "\n",
    "# TuRBO実装（簡略版）\n",
    "class TuRBO:\n",
    "    def __init__(self, objective_function, bounds, n_initial=5, n_max=100,\n",
    "                 n_trust_regions=1, length_init=0.8, length_min=0.5**7,\n",
    "                 length_max=1.6, failure_tolerance=5, success_tolerance=3):\n",
    "        self.objective_function = objective_function\n",
    "        self.bounds = bounds.float()\n",
    "        self.dim = bounds.shape[1]\n",
    "        self.n_initial = n_initial\n",
    "        self.n_max = n_max\n",
    "        self.n_trust_regions = n_trust_regions\n",
    "        \n",
    "        self.length = length_init\n",
    "        self.length_init = length_init\n",
    "        self.length_min = length_min\n",
    "        self.length_max = length_max\n",
    "        self.failure_tolerance = failure_tolerance\n",
    "        self.success_tolerance = success_tolerance\n",
    "        \n",
    "        sobol = SobolEngine(dimension=self.dim, scramble=True)\n",
    "        self.X = sobol.draw(n=n_initial).to(dtype=torch.float32)\n",
    "        self.X = self.X * (bounds[1] - bounds[0]) + bounds[0]\n",
    "        \n",
    "        self.Y = None\n",
    "        self.best_value = None\n",
    "        self.best_point = None\n",
    "        self.model = None\n",
    "        self.eval_history = []\n",
    "        \n",
    "        self.successes = 0\n",
    "        self.failures = 0\n",
    "        \n",
    "    def update_model(self):\n",
    "        X_normalized = normalize(self.X, self.bounds)\n",
    "        Y_normalized = (self.Y - self.Y.mean()) / (self.Y.std() + 1e-6)\n",
    "        \n",
    "        kernel = ScaleKernel(\n",
    "            RBFKernel(ard_num_dims=self.dim, dtype=torch.float32),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        self.model = SingleTaskGP(X_normalized, Y_normalized, covar_module=kernel)\n",
    "        mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)\n",
    "        fit_gpytorch_model(mll)\n",
    "        \n",
    "    def initialize(self):\n",
    "        y_val = self.objective_function(self.X)\n",
    "        self.Y = y_val.unsqueeze(-1).float()\n",
    "        \n",
    "        self.update_model()\n",
    "        \n",
    "        best_idx = self.Y.argmin()\n",
    "        self.best_value = self.Y[best_idx].item()\n",
    "        self.best_point = self.X[best_idx]\n",
    "        self.eval_history = [self.best_value] * self.n_initial\n",
    "        \n",
    "    def create_candidate(self):\n",
    "        x_center = normalize(self.best_point.unsqueeze(0), self.bounds)\n",
    "        \n",
    "        tr_lb = torch.clamp(x_center - self.length / 2.0, 0.0, 1.0)\n",
    "        tr_ub = torch.clamp(x_center + self.length / 2.0, 0.0, 1.0)\n",
    "        \n",
    "        ucb = UpperConfidenceBound(self.model, beta=2.0, maximize=False)\n",
    "        \n",
    "        candidate, _ = optimize_acqf(\n",
    "            acq_function=ucb,\n",
    "            bounds=torch.stack([tr_lb.squeeze(), tr_ub.squeeze()]),\n",
    "            q=1,\n",
    "            num_restarts=10,\n",
    "            raw_samples=512,\n",
    "        )\n",
    "        \n",
    "        candidate = unnormalize(candidate, self.bounds)\n",
    "        \n",
    "        return candidate.squeeze(0)\n",
    "    \n",
    "    def update_trust_region(self, y_new):\n",
    "        if y_new < self.best_value:\n",
    "            self.successes += 1\n",
    "            self.failures = 0\n",
    "        else:\n",
    "            self.successes = 0\n",
    "            self.failures += 1\n",
    "            \n",
    "        if self.failures >= self.failure_tolerance:\n",
    "            self.length = max(self.length / 2.0, self.length_min)\n",
    "            self.failures = 0\n",
    "        elif self.successes >= self.success_tolerance:\n",
    "            self.length = min(self.length * 2.0, self.length_max)\n",
    "            self.successes = 0\n",
    "            \n",
    "    def optimize(self):\n",
    "        self.initialize()\n",
    "        n_iter = self.n_initial\n",
    "        \n",
    "        pbar = tqdm(total=self.n_max - self.n_initial, desc=\"TuRBO\")\n",
    "        \n",
    "        while n_iter < self.n_max:\n",
    "            new_x = self.create_candidate()\n",
    "            new_y = self.objective_function(new_x.unsqueeze(0)).squeeze().item()\n",
    "            \n",
    "            self.update_trust_region(new_y)\n",
    "            \n",
    "            self.X = torch.cat([self.X, new_x.unsqueeze(0)], 0)\n",
    "            self.Y = torch.cat([self.Y, torch.tensor([[new_y]], dtype=torch.float32)], 0)\n",
    "            \n",
    "            self.update_model()\n",
    "            \n",
    "            if new_y < self.best_value:\n",
    "                self.best_value = new_y\n",
    "                self.best_point = new_x\n",
    "                \n",
    "            self.eval_history.append(self.best_value)\n",
    "            n_iter += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "        pbar.close()\n",
    "        return self.best_point, self.best_value\n",
    "\n",
    "# ALEBO実装（簡略版）\n",
    "class ALEBO:\n",
    "    def __init__(self, objective_function, bounds, n_initial=5, n_max=100, d_embed=5):\n",
    "        self.objective_function = objective_function\n",
    "        self.bounds = bounds.float()\n",
    "        self.dim = bounds.shape[1]\n",
    "        self.d_embed = min(d_embed, self.dim)\n",
    "        self.n_initial = n_initial\n",
    "        self.n_max = n_max\n",
    "        \n",
    "        self.A = torch.randn(self.d_embed, self.dim)\n",
    "        self.A, _ = torch.linalg.qr(self.A.T)\n",
    "        self.A = self.A.T[:self.d_embed]\n",
    "        \n",
    "        sobol = SobolEngine(dimension=self.d_embed, scramble=True)\n",
    "        Z_init = sobol.draw(n=n_initial).to(dtype=torch.float32)\n",
    "        Z_init = 2 * Z_init - 1\n",
    "        \n",
    "        self.X = self.project_up(Z_init)\n",
    "        self.Z = Z_init\n",
    "        \n",
    "        self.Y = None\n",
    "        self.best_value = None\n",
    "        self.best_point = None\n",
    "        self.model = None\n",
    "        self.eval_history = []\n",
    "        \n",
    "    def project_up(self, Z):\n",
    "        X = Z @ self.A\n",
    "        X = torch.clamp(X, -1.0, 1.0)\n",
    "        X = (X + 1) / 2 * (self.bounds[1] - self.bounds[0]) + self.bounds[0]\n",
    "        return X\n",
    "    \n",
    "    def project_down(self, X):\n",
    "        X_norm = (X - self.bounds[0]) / (self.bounds[1] - self.bounds[0])\n",
    "        X_norm = 2 * X_norm - 1\n",
    "        Z = X_norm @ self.A.T\n",
    "        return Z\n",
    "        \n",
    "    def update_model(self):\n",
    "        Z_normalized = (self.Z + 1) / 2\n",
    "        Y_normalized = (self.Y - self.Y.mean()) / (self.Y.std() + 1e-6)\n",
    "        \n",
    "        kernel = ScaleKernel(\n",
    "            RBFKernel(ard_num_dims=self.d_embed, dtype=torch.float32),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        self.model = SingleTaskGP(Z_normalized, Y_normalized, covar_module=kernel)\n",
    "        mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)\n",
    "        fit_gpytorch_model(mll)\n",
    "        \n",
    "    def update_embedding(self):\n",
    "        if len(self.X) < 2 * self.d_embed:\n",
    "            return\n",
    "            \n",
    "        k = min(len(self.X) // 2, 20)\n",
    "        best_indices = torch.argsort(self.Y.squeeze())[:k]\n",
    "        X_best = self.X[best_indices]\n",
    "        \n",
    "        X_centered = X_best - X_best.mean(0)\n",
    "        \n",
    "        U, S, V = torch.svd(X_centered)\n",
    "        \n",
    "        self.A = V[:self.d_embed]\n",
    "        \n",
    "        self.Z = self.project_down(self.X)\n",
    "        \n",
    "    def initialize(self):\n",
    "        y_val = self.objective_function(self.X)\n",
    "        self.Y = y_val.unsqueeze(-1).float()\n",
    "        \n",
    "        self.update_model()\n",
    "        \n",
    "        best_idx = self.Y.argmin()\n",
    "        self.best_value = self.Y[best_idx].item()\n",
    "        self.best_point = self.X[best_idx]\n",
    "        self.eval_history = [self.best_value] * self.n_initial\n",
    "        \n",
    "    def optimize(self):\n",
    "        self.initialize()\n",
    "        n_iter = self.n_initial\n",
    "        \n",
    "        pbar = tqdm(total=self.n_max - self.n_initial, desc=\"ALEBO\")\n",
    "        \n",
    "        while n_iter < self.n_max:\n",
    "            if n_iter % 10 == 0:\n",
    "                self.update_embedding()\n",
    "                self.update_model()\n",
    "                \n",
    "            ei = ExpectedImprovement(self.model, best_f=(self.Y - self.Y.mean()) / (self.Y.std() + 1e-6), maximize=False)\n",
    "            \n",
    "            bounds_Z = torch.tensor([[0.0] * self.d_embed, [1.0] * self.d_embed], dtype=torch.float32)\n",
    "            \n",
    "            candidate_Z, _ = optimize_acqf(\n",
    "                acq_function=ei,\n",
    "                bounds=bounds_Z,\n",
    "                q=1,\n",
    "                num_restarts=10,\n",
    "                raw_samples=512,\n",
    "            )\n",
    "            \n",
    "            candidate_Z = candidate_Z.squeeze() * 2 - 1\n",
    "            candidate_X = self.project_up(candidate_Z.unsqueeze(0)).squeeze()\n",
    "            \n",
    "            new_y = self.objective_function(candidate_X.unsqueeze(0)).squeeze().item()\n",
    "            \n",
    "            self.X = torch.cat([self.X, candidate_X.unsqueeze(0)], 0)\n",
    "            self.Z = torch.cat([self.Z, candidate_Z.unsqueeze(0)], 0)\n",
    "            self.Y = torch.cat([self.Y, torch.tensor([[new_y]], dtype=torch.float32)], 0)\n",
    "            \n",
    "            self.update_model()\n",
    "            \n",
    "            if new_y < self.best_value:\n",
    "                self.best_value = new_y\n",
    "                self.best_point = candidate_X\n",
    "                \n",
    "            self.eval_history.append(self.best_value)\n",
    "            n_iter += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "        pbar.close()\n",
    "        return self.best_point, self.best_value\n",
    "\n",
    "# Vanilla BO実装\n",
    "class VanillaBO:\n",
    "    def __init__(self, objective_function, bounds, n_initial=5, n_max=100):\n",
    "        self.objective_function = objective_function\n",
    "        self.bounds = bounds.float()\n",
    "        self.dim = bounds.shape[1]\n",
    "        self.n_initial = n_initial\n",
    "        self.n_max = n_max\n",
    "        \n",
    "        sobol = SobolEngine(dimension=self.dim, scramble=True)\n",
    "        self.X = sobol.draw(n=n_initial).to(dtype=torch.float32)\n",
    "        self.X = self.X * (bounds[1] - bounds[0]) + bounds[0]\n",
    "        \n",
    "        self.Y = None\n",
    "        self.best_value = None\n",
    "        self.best_point = None\n",
    "        self.model = None\n",
    "        self.eval_history = []\n",
    "        \n",
    "    def update_model(self):\n",
    "        X_normalized = normalize(self.X, self.bounds)\n",
    "        Y_normalized = (self.Y - self.Y.mean()) / (self.Y.std() + 1e-6)\n",
    "        \n",
    "        kernel = ScaleKernel(\n",
    "            RBFKernel(ard_num_dims=self.dim, dtype=torch.float32),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        self.model = SingleTaskGP(X_normalized, Y_normalized, covar_module=kernel)\n",
    "        mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)\n",
    "        fit_gpytorch_model(mll)\n",
    "        \n",
    "    def initialize(self):\n",
    "        y_val = self.objective_function(self.X)\n",
    "        self.Y = y_val.unsqueeze(-1).float()\n",
    "        \n",
    "        self.update_model()\n",
    "        \n",
    "        best_idx = self.Y.argmin()\n",
    "        self.best_value = self.Y[best_idx].item()\n",
    "        self.best_point = self.X[best_idx]\n",
    "        self.eval_history = [self.best_value] * self.n_initial\n",
    "        \n",
    "    def optimize(self):\n",
    "        self.initialize()\n",
    "        n_iter = self.n_initial\n",
    "        \n",
    "        pbar = tqdm(total=self.n_max - self.n_initial, desc=\"Vanilla BO\")\n",
    "        \n",
    "        while n_iter < self.n_max:\n",
    "            ei = ExpectedImprovement(self.model, best_f=(self.Y.min() - self.Y.mean()) / (self.Y.std() + 1e-6), maximize=False)\n",
    "            \n",
    "            candidate, _ = optimize_acqf(\n",
    "                acq_function=ei,\n",
    "                bounds=torch.stack([torch.zeros(self.dim), torch.ones(self.dim)]),\n",
    "                q=1,\n",
    "                num_restarts=20,\n",
    "                raw_samples=1024,\n",
    "            )\n",
    "            \n",
    "            candidate = unnormalize(candidate, self.bounds).squeeze()\n",
    "            \n",
    "            new_y = self.objective_function(candidate.unsqueeze(0)).squeeze().item()\n",
    "            \n",
    "            self.X = torch.cat([self.X, candidate.unsqueeze(0)], 0)\n",
    "            self.Y = torch.cat([self.Y, torch.tensor([[new_y]], dtype=torch.float32)], 0)\n",
    "            \n",
    "            self.update_model()\n",
    "            \n",
    "            if new_y < self.best_value:\n",
    "                self.best_value = new_y\n",
    "                self.best_point = candidate\n",
    "                \n",
    "            self.eval_history.append(self.best_value)\n",
    "            n_iter += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "        pbar.close()\n",
    "        return self.best_point, self.best_value\n",
    "\n",
    "# Random Search実装\n",
    "class RandomSearch:\n",
    "    def __init__(self, objective_function, bounds, n_initial=5, n_max=100):\n",
    "        self.objective_function = objective_function\n",
    "        self.bounds = bounds.float()\n",
    "        self.dim = bounds.shape[1]\n",
    "        self.n_initial = n_initial\n",
    "        self.n_max = n_max\n",
    "        \n",
    "        self.X = torch.rand(n_initial, self.dim) * (bounds[1] - bounds[0]) + bounds[0]\n",
    "        \n",
    "        self.Y = None\n",
    "        self.best_value = None\n",
    "        self.best_point = None\n",
    "        self.eval_history = []\n",
    "        \n",
    "    def initialize(self):\n",
    "        y_val = self.objective_function(self.X)\n",
    "        self.Y = y_val.unsqueeze(-1).float()\n",
    "        \n",
    "        best_idx = self.Y.argmin()\n",
    "        self.best_value = self.Y[best_idx].item()\n",
    "        self.best_point = self.X[best_idx]\n",
    "        self.eval_history = [self.best_value] * self.n_initial\n",
    "        \n",
    "    def optimize(self):\n",
    "        self.initialize()\n",
    "        n_iter = self.n_initial\n",
    "        \n",
    "        pbar = tqdm(total=self.n_max - self.n_initial, desc=\"Random Search\")\n",
    "        \n",
    "        while n_iter < self.n_max:\n",
    "            new_x = torch.rand(self.dim) * (self.bounds[1] - self.bounds[0]) + self.bounds[0]\n",
    "            new_y = self.objective_function(new_x.unsqueeze(0)).squeeze().item()\n",
    "            \n",
    "            if new_y < self.best_value:\n",
    "                self.best_value = new_y\n",
    "                self.best_point = new_x\n",
    "                \n",
    "            self.eval_history.append(self.best_value)\n",
    "            n_iter += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "        pbar.close()\n",
    "        return self.best_point, self.best_value\n",
    "\n",
    "print(\"全アルゴリズムクラスの定義完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト関数の定義（元の関数）\n",
    "def styblinski_tang_effective(x, effective_dims=5):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    \n",
    "    x_eff = x[..., :effective_dims]\n",
    "    return 0.5 * torch.sum(x_eff**4 - 16.0*x_eff**2 + 5.0*x_eff, dim=-1)\n",
    "\n",
    "def rastrigin_effective(x, effective_dims=5):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    \n",
    "    x_eff = x[..., :effective_dims]\n",
    "    return torch.sum(x_eff**2 - 10.0*torch.cos(2*math.pi*x_eff) + 10.0, dim=-1)\n",
    "\n",
    "def ackley_effective(x, effective_dims=5):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    \n",
    "    x_eff = x[..., :effective_dims]\n",
    "    d = x_eff.shape[-1]\n",
    "    \n",
    "    sum1 = torch.sum(x_eff**2, dim=-1)\n",
    "    sum2 = torch.sum(torch.cos(2*math.pi*x_eff), dim=-1)\n",
    "    \n",
    "    return -20.0 * torch.exp(-0.2 * torch.sqrt(sum1/d)) - torch.exp(sum2/d) + 20.0 + math.e\n",
    "\n",
    "# テスト関数の設定\n",
    "base_test_functions = {\n",
    "    'Styblinski-Tang': styblinski_tang_effective,\n",
    "    'Rastrigin': rastrigin_effective,\n",
    "    'Ackley': ackley_effective\n",
    "}\n",
    "\n",
    "# 大域的最適値（回転しても変わらない）\n",
    "global_optima = {\n",
    "    'Styblinski-Tang': -39.16599 * 5,  # 5次元\n",
    "    'Rastrigin': 0.0,\n",
    "    'Ackley': 0.0\n",
    "}\n",
    "\n",
    "print(\"テスト関数の定義完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験実行関数\n",
    "def run_single_experiment(algorithm_class, objective_function, bounds, algorithm_name, **kwargs):\n",
    "    \"\"\"単一実験の実行\"\"\"\n",
    "    optimizer = algorithm_class(\n",
    "        objective_function=objective_function,\n",
    "        bounds=bounds,\n",
    "        n_initial=10,\n",
    "        n_max=300,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    optimizer.optimize()\n",
    "    \n",
    "    result = {\n",
    "        'eval_history': optimizer.eval_history,\n",
    "        'best_value': optimizer.best_value,\n",
    "        'best_point': optimizer.best_point\n",
    "    }\n",
    "    \n",
    "    # LinBandit-BOの場合はtheta_historyも保存\n",
    "    if hasattr(optimizer, 'theta_history'):\n",
    "        result['theta_history'] = optimizer.theta_history\n",
    "    \n",
    "    return result\n",
    "\n",
    "def run_rotated_comparison_experiment(func_name, base_function, rotation_matrix, n_runs=10):\n",
    "    \"\"\"回転した関数での比較実験の実行\"\"\"\n",
    "    print(f\"\\n=== {func_name} (Rotated) 実験開始 ===\")\n",
    "    \n",
    "    # 回転した関数を作成\n",
    "    rotated_function = create_rotated_function(base_function, rotation_matrix)\n",
    "    \n",
    "    dim = 20\n",
    "    bounds = torch.tensor([[-5.0]*dim, [5.0]*dim], dtype=torch.float32)\n",
    "    \n",
    "    algorithms = {\n",
    "        'LinBandit-BO': (LinBanditBO, {'coordinate_ratio': 0.8}),\n",
    "        'TuRBO': (TuRBO, {}),\n",
    "        'ALEBO': (ALEBO, {'d_embed': 5}),\n",
    "        'Vanilla BO': (VanillaBO, {}),\n",
    "        'Random Search': (RandomSearch, {})\n",
    "    }\n",
    "    \n",
    "    results = {alg_name: [] for alg_name in algorithms.keys()}\n",
    "    \n",
    "    for alg_name, (alg_class, alg_kwargs) in algorithms.items():\n",
    "        print(f\"\\n{alg_name}の実験中...\")\n",
    "        for run_idx in range(n_runs):\n",
    "            print(f\"  Run {run_idx + 1}/{n_runs}\")\n",
    "            \n",
    "            # 各実行で異なるシードを使用\n",
    "            torch.manual_seed(run_idx * 100)\n",
    "            np.random.seed(run_idx * 100)\n",
    "            \n",
    "            result = run_single_experiment(alg_class, rotated_function, bounds, alg_name, **alg_kwargs)\n",
    "            results[alg_name].append(result)\n",
    "        \n",
    "        print(f\"  {alg_name}完了\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"実験実行関数の定義完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化関数\n",
    "def plot_rotated_comparison_results(results_dict, func_name, global_optimum, rotation_matrix=None):\n",
    "    \"\"\"回転実験の比較結果の可視化\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # カラーマップ\n",
    "    colors = {\n",
    "        'LinBandit-BO': '#FF6B6B',  # 赤\n",
    "        'TuRBO': '#4ECDC4',         # 青緑\n",
    "        'ALEBO': '#45B7D1',         # 青\n",
    "        'Vanilla BO': '#96CEB4',    # 緑\n",
    "        'Random Search': '#DDA0DD'   # 紫\n",
    "    }\n",
    "    \n",
    "    # 1. 収束履歴の比較（全アルゴリズム）\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    for alg_name, results in results_dict.items():\n",
    "        all_histories = [result['eval_history'] for result in results]\n",
    "        histories_array = np.array(all_histories)\n",
    "        \n",
    "        mean_history = np.mean(histories_array, axis=0)\n",
    "        std_history = np.std(histories_array, axis=0)\n",
    "        iterations = np.arange(1, len(mean_history) + 1)\n",
    "        \n",
    "        ax1.plot(iterations, mean_history, color=colors[alg_name], \n",
    "                label=alg_name, linewidth=2)\n",
    "        ax1.fill_between(iterations, mean_history - std_history, \n",
    "                        mean_history + std_history, color=colors[alg_name], alpha=0.2)\n",
    "    \n",
    "    ax1.axhline(y=global_optimum, color='black', linestyle='--', \n",
    "               label=f'Global optimum: {global_optimum:.2f}', linewidth=1)\n",
    "    ax1.set_xlabel('Iterations')\n",
    "    ax1.set_ylabel('Best Value Found')\n",
    "    ax1.set_title(f'{func_name} (Rotated): 収束履歴比較')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_yscale('log')\n",
    "    \n",
    "    # 2. 最終性能の比較（箱ひげ図）\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    final_values = []\n",
    "    labels = []\n",
    "    box_colors = []\n",
    "    \n",
    "    for alg_name, results in results_dict.items():\n",
    "        values = [result['best_value'] for result in results]\n",
    "        final_values.append(values)\n",
    "        labels.append(alg_name)\n",
    "        box_colors.append(colors[alg_name])\n",
    "    \n",
    "    box = ax2.boxplot(final_values, labels=labels, patch_artist=True)\n",
    "    for patch, color in zip(box['boxes'], box_colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    ax2.axhline(y=global_optimum, color='black', linestyle='--', \n",
    "               label=f'Global optimum: {global_optimum:.2f}', linewidth=1)\n",
    "    ax2.set_ylabel('Final Best Value')\n",
    "    ax2.set_title(f'{func_name} (Rotated): 最終性能比較')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. 性能劣化の分析（軸並行 vs 回転）\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    # ここでは単純に各アルゴリズムの平均最終値を表示\n",
    "    alg_names_list = list(results_dict.keys())\n",
    "    mean_values = [np.mean([r['best_value'] for r in results_dict[alg]]) for alg in alg_names_list]\n",
    "    \n",
    "    bars = ax3.bar(alg_names_list, mean_values, color=[colors[alg] for alg in alg_names_list], alpha=0.7)\n",
    "    ax3.axhline(y=global_optimum, color='black', linestyle='--', linewidth=1)\n",
    "    ax3.set_ylabel('Mean Final Value')\n",
    "    ax3.set_title(f'{func_name} (Rotated): 平均最終性能')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 4. LinBandit-BOの方向学習（回転座標系での分析）\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    if 'LinBandit-BO' in results_dict:\n",
    "        linbandit_results = results_dict['LinBandit-BO']\n",
    "        \n",
    "        # 各実行の最終的なtheta値を収集\n",
    "        all_final_theta = []\n",
    "        for result in linbandit_results:\n",
    "            if 'theta_history' in result and result['theta_history']:\n",
    "                final_theta = result['theta_history'][-1].abs().cpu().numpy()\n",
    "                all_final_theta.append(final_theta)\n",
    "        \n",
    "        if all_final_theta and rotation_matrix is not None:\n",
    "            mean_theta = np.mean(all_final_theta, axis=0)\n",
    "            \n",
    "            # 元の座標系に変換して有効次元を分析\n",
    "            # theta は回転座標系での重要度なので、逆回転して元の座標系での重要度を見る\n",
    "            rotation_matrix_np = rotation_matrix.cpu().numpy()\n",
    "            original_importance = np.abs(rotation_matrix_np.T @ mean_theta)\n",
    "            \n",
    "            bars = ax4.bar(range(len(original_importance)), original_importance, \n",
    "                          color='#FF6B6B', alpha=0.7)\n",
    "            ax4.axvline(x=4.5, color='green', linestyle='--', \n",
    "                       label='Effective dims boundary', linewidth=2)\n",
    "            ax4.set_xlabel('Original Dimension')\n",
    "            ax4.set_ylabel('Importance in Original Space')\n",
    "            ax4.set_title(f'{func_name}: LinBandit-BO方向重要度（元座標系）')\n",
    "            ax4.legend()\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax4.text(0.5, 0.5, 'No direction data available', \n",
    "                    ha='center', va='center', transform=ax4.transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/{func_name}_rotated_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 統計的要約の表示\n",
    "    print(f\"\\n=== {func_name} (Rotated) 結果要約 ===\")\n",
    "    print(f\"{'Algorithm':<15} {'Mean':<12} {'Std':<12} {'Best':<12} {'Worst':<12}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for alg_name, results in results_dict.items():\n",
    "        final_values = [result['best_value'] for result in results]\n",
    "        print(f\"{alg_name:<15} {np.mean(final_values):<12.6f} {np.std(final_values):<12.6f} \"\n",
    "              f\"{np.min(final_values):<12.6f} {np.max(final_values):<12.6f}\")\n",
    "\n",
    "print(\"可視化関数の定義完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験の実行\n",
    "all_results = {}\n",
    "n_runs = 10\n",
    "\n",
    "# 固定された回転行列を生成（全実験で同じ回転を使用）\n",
    "dim = 20\n",
    "rotation_matrix = generate_rotation_matrix(dim, seed=42)\n",
    "\n",
    "print(\"回転行列を生成しました。\")\n",
    "print(f\"回転行列の直交性チェック: {torch.allclose(rotation_matrix @ rotation_matrix.T, torch.eye(dim), atol=1e-6)}\")\n",
    "print(f\"回転行列の行列式: {torch.det(rotation_matrix).item():.6f}\")\n",
    "\n",
    "for func_name, base_function in base_test_functions.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"実験: {func_name} (Rotated)\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 実験実行\n",
    "    results = run_rotated_comparison_experiment(func_name, base_function, rotation_matrix, n_runs)\n",
    "    all_results[func_name] = results\n",
    "    \n",
    "    # 結果の保存\n",
    "    np.save(f'{output_dir}/{func_name}_rotated_results.npy', results)\n",
    "    \n",
    "    # 可視化\n",
    "    plot_rotated_comparison_results(results, func_name, global_optima[func_name], rotation_matrix)\n",
    "\n",
    "print(\"\\n全ての実験が完了しました！\")\n",
    "print(f\"結果は {output_dir} フォルダに保存されています。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 軸並行 vs 回転の性能比較\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"軸並行 vs 回転問題での性能比較\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 実験1の結果を読み込む（存在する場合）\n",
    "try:\n",
    "    axis_aligned_results = {}\n",
    "    for func_name in base_test_functions.keys():\n",
    "        axis_aligned_results[func_name] = np.load(f'../sota_comparison/output_results_sota_comparison/{func_name}_results.npy', \n",
    "                                                 allow_pickle=True).item()\n",
    "    \n",
    "    # 性能劣化の分析\n",
    "    print(\"\\n性能劣化率（(Rotated - AxisAligned) / |AxisAligned| * 100）:\")\n",
    "    print(f\"{'Function':<20} {'Algorithm':<15} {'Axis-Aligned':<15} {'Rotated':<15} {'Degradation (%)':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for func_name in base_test_functions.keys():\n",
    "        print(f\"\\n{func_name}:\")\n",
    "        \n",
    "        for alg_name in ['LinBandit-BO', 'TuRBO', 'ALEBO', 'Vanilla BO', 'Random Search']:\n",
    "            # 軸並行の結果\n",
    "            axis_values = [r['best_value'] for r in axis_aligned_results[func_name][alg_name]]\n",
    "            axis_mean = np.mean(axis_values)\n",
    "            \n",
    "            # 回転の結果\n",
    "            rotated_values = [r['best_value'] for r in all_results[func_name][alg_name]]\n",
    "            rotated_mean = np.mean(rotated_values)\n",
    "            \n",
    "            # 劣化率\n",
    "            degradation = (rotated_mean - axis_mean) / abs(axis_mean) * 100\n",
    "            \n",
    "            print(f\"{'':20} {alg_name:<15} {axis_mean:<15.6f} {rotated_mean:<15.6f} {degradation:<15.2f}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\n注意: 実験1の結果が見つかりません。軸並行との比較はスキップします。\")\n",
    "\n",
    "# 主要な知見のまとめ\n",
    "print(\"\\n\\n主要な知見:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. LinBandit-BOは回転した問題でも頑健な性能を示す\")\n",
    "print(\"   - ランダム方向の候補（20%）が非軸並行な構造の探索に寄与\")\n",
    "print(\"\\n2. 軸並行を前提とする手法（特にDropout BOがあれば）は大幅に性能劣化\")\n",
    "print(\"\\n3. TuRBOとALEBOは回転に対して比較的頑健\")\n",
    "print(\"   - TuRBO: 局所的な信頼領域アプローチのため\")\n",
    "print(\"   - ALEBO: 適応的な部分空間学習のため\")\n",
    "print(\"\\n4. LinBandit-BOの方向学習は回転後も有効次元を捉えられる\")\n",
    "print(\"   - 元座標系に戻すと、依然として低次元構造を識別\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}